{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a7e48abcca0618372ed56cbcc979249f4beb77f"
   },
   "source": [
    "# Default Kaggle kernel line:  Show the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '2018-10-08', 'combine_validation_csv.ipynb', 'data', 'File_creator.ipynb', 'input', 'kernel.ipynb', 'labs_lecture13', 'output', 'pretrained', 'sample_submission.csv', 'test_raw.csv', 'train_raw', 'train_raw.zip', 'train_simplified.zip'] \n",
      "\n",
      "['..data', '.ipynb_checkpoints', 'Fork_linc_ResNet.ipynb', 'kernel_1621.ipynb', 'linc_resnet (2)-Copy1.ipynb', 'linc_resnet (2)-Copy2.ipynb', 'linc_resnet (2).ipynb', 'linc_ResNet.ipynb', 'load files.ipynb', 'test_simplified.csv', 'train_simplified', 'Untitled.ipynb', 'validation_aye.csv'] \n",
      "\n",
      "['airplane.csv', 'alarm clock.csv', 'ambulance.csv', 'angel.csv', 'animal migration.csv', 'ant.csv', 'anvil.csv', 'apple.csv', 'arm.csv', 'asparagus.csv', 'axe.csv', 'backpack.csv', 'banana.csv', 'bandage.csv', 'barn.csv', 'baseball bat.csv', 'baseball.csv', 'basket.csv', 'basketball.csv', 'bat.csv', 'bathtub.csv', 'beach.csv', 'bear.csv', 'beard.csv', 'bed.csv', 'bee.csv', 'belt.csv', 'bench.csv', 'bicycle.csv', 'binoculars.csv', 'bird.csv', 'birthday cake.csv', 'blackberry.csv', 'blueberry.csv', 'book.csv', 'boomerang.csv', 'bottlecap.csv', 'bowtie.csv', 'bracelet.csv', 'brain.csv', 'bread.csv', 'bridge.csv', 'broccoli.csv', 'broom.csv', 'bucket.csv', 'bulldozer.csv', 'bus.csv', 'bush.csv', 'butterfly.csv', 'cactus.csv', 'cake.csv', 'calculator.csv', 'calendar.csv', 'camel.csv', 'camera.csv', 'camouflage.csv', 'campfire.csv', 'candle.csv', 'cannon.csv', 'canoe.csv', 'car.csv', 'carrot.csv', 'castle.csv', 'cat.csv', 'ceiling fan.csv', 'cell phone.csv', 'cello.csv', 'chair.csv', 'chandelier.csv', 'church.csv', 'circle.csv', 'clarinet.csv', 'clock.csv', 'cloud.csv', 'coffee cup.csv', 'compass.csv', 'computer.csv', 'cookie.csv', 'cooler.csv', 'couch.csv', 'cow.csv', 'crab.csv', 'crayon.csv', 'crocodile.csv', 'crown.csv', 'cruise ship.csv', 'cup.csv', 'diamond.csv', 'dishwasher.csv', 'diving board.csv', 'dog.csv', 'dolphin.csv', 'donut.csv', 'door.csv', 'dragon.csv', 'dresser.csv', 'drill.csv', 'drums.csv', 'duck.csv', 'dumbbell.csv', 'ear.csv', 'elbow.csv', 'elephant.csv', 'envelope.csv', 'eraser.csv', 'eye.csv', 'eyeglasses.csv', 'face.csv', 'fan.csv', 'feather.csv', 'fence.csv', 'finger.csv', 'fire hydrant.csv', 'fireplace.csv', 'firetruck.csv', 'fish.csv', 'flamingo.csv', 'flashlight.csv', 'flip flops.csv', 'floor lamp.csv', 'flower.csv', 'flying saucer.csv', 'foot.csv', 'fork.csv', 'frog.csv', 'frying pan.csv', 'garden hose.csv', 'garden.csv', 'giraffe.csv', 'goatee.csv', 'golf club.csv', 'grapes.csv', 'grass.csv', 'guitar.csv', 'hamburger.csv', 'hammer.csv', 'hand.csv', 'harp.csv', 'hat.csv', 'headphones.csv', 'hedgehog.csv', 'helicopter.csv', 'helmet.csv', 'hexagon.csv', 'hockey puck.csv', 'hockey stick.csv', 'horse.csv', 'hospital.csv', 'hot air balloon.csv', 'hot dog.csv', 'hot tub.csv', 'hourglass.csv', 'house plant.csv', 'house.csv', 'hurricane.csv', 'ice cream.csv', 'jacket.csv', 'jail.csv', 'kangaroo.csv', 'key.csv', 'keyboard.csv', 'knee.csv', 'ladder.csv', 'lantern.csv', 'laptop.csv', 'leaf.csv', 'leg.csv', 'light bulb.csv', 'lighthouse.csv', 'lightning.csv', 'line.csv', 'lion.csv', 'lipstick.csv', 'lobster.csv', 'lollipop.csv', 'mailbox.csv', 'map.csv', 'marker.csv', 'matches.csv', 'megaphone.csv', 'mermaid.csv', 'microphone.csv', 'microwave.csv', 'monkey.csv', 'moon.csv', 'mosquito.csv', 'motorbike.csv', 'mountain.csv', 'mouse.csv', 'moustache.csv', 'mouth.csv', 'mug.csv', 'mushroom.csv', 'nail.csv', 'necklace.csv', 'nose.csv', 'ocean.csv', 'octagon.csv', 'octopus.csv', 'onion.csv', 'oven.csv', 'owl.csv', 'paint can.csv', 'paintbrush.csv', 'palm tree.csv', 'panda.csv', 'pants.csv', 'paper clip.csv', 'parachute.csv', 'parrot.csv', 'passport.csv', 'peanut.csv', 'pear.csv', 'peas.csv', 'pencil.csv', 'penguin.csv', 'piano.csv', 'pickup truck.csv', 'picture frame.csv', 'pig.csv', 'pillow.csv', 'pineapple.csv', 'pizza.csv', 'pliers.csv', 'police car.csv', 'pond.csv', 'pool.csv', 'popsicle.csv', 'postcard.csv', 'potato.csv', 'power outlet.csv', 'purse.csv', 'rabbit.csv', 'raccoon.csv', 'radio.csv', 'rain.csv', 'rainbow.csv', 'rake.csv', 'remote control.csv', 'rhinoceros.csv', 'river.csv', 'roller coaster.csv', 'rollerskates.csv', 'sailboat.csv', 'sandwich.csv', 'saw.csv', 'saxophone.csv', 'school bus.csv', 'scissors.csv', 'scorpion.csv', 'screwdriver.csv', 'sea turtle.csv', 'see saw.csv', 'shark.csv', 'sheep.csv', 'shoe.csv', 'shorts.csv', 'shovel.csv', 'sink.csv', 'skateboard.csv', 'skull.csv', 'skyscraper.csv', 'sleeping bag.csv', 'smiley face.csv', 'snail.csv', 'snake.csv', 'snorkel.csv', 'snowflake.csv', 'snowman.csv', 'soccer ball.csv', 'sock.csv', 'speedboat.csv', 'spider.csv', 'spoon.csv', 'spreadsheet.csv', 'square.csv', 'squiggle.csv', 'squirrel.csv', 'stairs.csv', 'star.csv', 'steak.csv', 'stereo.csv', 'stethoscope.csv', 'stitches.csv', 'stop sign.csv', 'stove.csv', 'strawberry.csv', 'streetlight.csv', 'string bean.csv', 'submarine.csv', 'suitcase.csv', 'sun.csv', 'swan.csv', 'sweater.csv', 'swing set.csv', 'sword.csv', 't-shirt.csv', 'table.csv', 'teapot.csv', 'teddy-bear.csv', 'telephone.csv', 'television.csv', 'tennis racquet.csv', 'tent.csv', 'The Eiffel Tower.csv', 'The Great Wall of China.csv', 'The Mona Lisa.csv', 'tiger.csv', 'toaster.csv', 'toe.csv', 'toilet.csv', 'tooth.csv', 'toothbrush.csv', 'toothpaste.csv', 'tornado.csv', 'tractor.csv', 'traffic light.csv', 'train.csv', 'tree.csv', 'triangle.csv', 'trombone.csv', 'truck.csv', 'trumpet.csv', 'umbrella.csv', 'underwear.csv', 'van.csv', 'vase.csv', 'violin.csv', 'washing machine.csv', 'watermelon.csv', 'waterslide.csv', 'whale.csv', 'wheel.csv', 'windmill.csv', 'wine bottle.csv', 'wine glass.csv', 'wristwatch.csv', 'yoga.csv', 'zebra.csv', 'zigzag.csv'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "#import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../\"),'\\n')\n",
    "print(os.listdir(\"../input\"), '\\n')\n",
    "print(os.listdir(\"../input/train_simplified\"), '\\n')\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# 1.1 Kaggle - Quickdraw: ResNet\n",
    "###        Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "439def5d5cfd28c1a93ad1602c240896718776eb"
   },
   "outputs": [],
   "source": [
    "# std libs\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "from glob import glob\n",
    "from timeit import default_timer as timer\n",
    "import gc\n",
    "\n",
    "#Pytorch libs\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "\n",
    "\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "941ed357a5fb7b48df260be43a3dce5e51977890"
   },
   "source": [
    "# 1.2 Setting up gpu\n",
    "   * Optimising gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9644373e20da48dae67582ab1d152aa2ab7f0642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set random seed\n",
      "\tSEED = 35202\n",
      "\tset cuda environment\n",
      "\t\ttorch.__version__              = 0.4.1\n",
      "\t\ttorch.version.cuda             = 9.0\n",
      "\t\ttorch.backends.cudnn.versiaon() = 7005\n",
      "\t\tos['CUDA_VISIBLE_DEVICES']     = None\n",
      "\t\ttorch.cuda.device_count()      = 1\n",
      "\tDevice used:  cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEED = 35202\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "print('Set random seed')\n",
    "print('\\tSEED = %d'%SEED)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "torch.backends.cudnn.enabled   = True\n",
    "print ('\\tset cuda environment')\n",
    "print ('\\t\\ttorch.__version__              =', torch.__version__)\n",
    "print ('\\t\\ttorch.version.cuda             =', torch.version.cuda)\n",
    "print ('\\t\\ttorch.backends.cudnn.versiaon() =', torch.backends.cudnn.version())\n",
    "try:\n",
    "    print ('\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     =',os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "    NUM_CUDA_DEVICES = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\n",
    "except Exception:\n",
    "    print ('\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     =','None')\n",
    "    NUM_CUDA_DEVICES = 1\n",
    "\n",
    "print ('\\t\\ttorch.cuda.device_count()      =', torch.cuda.device_count())\n",
    "    #print ('\\t\\ttorch.cuda.current_device()    =', torch.cuda.current_device())\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('\\tDevice used: ',device)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94b676d9d03ce0177ae27f97d675e3bcd85724f0"
   },
   "source": [
    "# 1.3 Data Processing\n",
    "* Extracting data; spliting them into train and eval (train_simplified.csv will be used)\n",
    "* Image Generation from Stroke\n",
    "* Raw trained data split into two files(Train and Eval) given by indices.\n",
    "In this way we know which are being referenced, instead of loading them and dividing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "746bafe1810c86585857acd5bbaa4c23e78710f1"
   },
   "source": [
    "## 1.3.1 Visualise the data\n",
    "### control the *'data_len'* to display the number of class output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4d4e0ee636763a472b80fa4b6426ad2fabc0d6fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrycode</th>\n",
       "      <th>drawing</th>\n",
       "      <th>key_id</th>\n",
       "      <th>recognized</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[167, 109, 80, 69, 58, 31, 57, 117, 99, 52, ...</td>\n",
       "      <td>5152802093400064</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-08 21:12:07.266040</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[90, 88, 95, 104, 112, 122], [65, 31, 12, 0,...</td>\n",
       "      <td>6577010312740864</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-23 02:08:35.229980</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[111, 148, 161, 175, 199, 218, 231, 236, 234...</td>\n",
       "      <td>5159910851477504</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-21 13:02:16.246170</td>\n",
       "      <td>alarm clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[154, 144, 129, 86, 66, 45, 45, 50, 76, 111,...</td>\n",
       "      <td>4608088873107456</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-01 21:42:04.745090</td>\n",
       "      <td>alarm clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[13, 10, 12, 20, 39, 67, 170, 196, 213, 220,...</td>\n",
       "      <td>5404586804248576</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-24 12:58:28.487110</td>\n",
       "      <td>ambulance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[9, 8, 0, 1, 5, 117, 166, 206, 216, 221, 249...</td>\n",
       "      <td>5731655589298176</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-28 15:53:40.978600</td>\n",
       "      <td>ambulance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[128, 116, 99, 87, 77, 75, 80, 90, 114, 130,...</td>\n",
       "      <td>6665588124418048</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-03 20:39:08.851890</td>\n",
       "      <td>angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JP</td>\n",
       "      <td>[[[98, 74, 52, 46, 44, 52, 63, 82, 116, 137, 1...</td>\n",
       "      <td>5275268287561728</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-05 05:52:48.496610</td>\n",
       "      <td>angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HR</td>\n",
       "      <td>[[[19, 52], [44, 50]], [[0, 0, 5], [56, 65, 69...</td>\n",
       "      <td>4975017072787456</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-22 11:34:53.899460</td>\n",
       "      <td>animal migration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 3, 12, 23, 40, 47, 53, 53, 49, 68, 88, 1...</td>\n",
       "      <td>4993426342805504</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-25 02:43:14.994860</td>\n",
       "      <td>animal migration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[27, 17, 16, 21, 34, 50, 49, 34, 23, 17], [4...</td>\n",
       "      <td>5421013154136064</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-27 00:14:57.310330</td>\n",
       "      <td>ant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[27, 0, 7, 40, 47, 20], [0, 41, 74, 73, 41, ...</td>\n",
       "      <td>4836123148812288</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-06 20:00:22.521560</td>\n",
       "      <td>ant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countrycode                                            drawing  \\\n",
       "0           US  [[[167, 109, 80, 69, 58, 31, 57, 117, 99, 52, ...   \n",
       "1           US  [[[90, 88, 95, 104, 112, 122], [65, 31, 12, 0,...   \n",
       "2           US  [[[111, 148, 161, 175, 199, 218, 231, 236, 234...   \n",
       "3           US  [[[154, 144, 129, 86, 66, 45, 45, 50, 76, 111,...   \n",
       "4           US  [[[13, 10, 12, 20, 39, 67, 170, 196, 213, 220,...   \n",
       "5           US  [[[9, 8, 0, 1, 5, 117, 166, 206, 216, 221, 249...   \n",
       "6           US  [[[128, 116, 99, 87, 77, 75, 80, 90, 114, 130,...   \n",
       "7           JP  [[[98, 74, 52, 46, 44, 52, 63, 82, 116, 137, 1...   \n",
       "8           HR  [[[19, 52], [44, 50]], [[0, 0, 5], [56, 65, 69...   \n",
       "9           US  [[[0, 3, 12, 23, 40, 47, 53, 53, 49, 68, 88, 1...   \n",
       "10          US  [[[27, 17, 16, 21, 34, 50, 49, 34, 23, 17], [4...   \n",
       "11          US  [[[27, 0, 7, 40, 47, 20], [0, 41, 74, 73, 41, ...   \n",
       "\n",
       "              key_id recognized                   timestamp              word  \n",
       "0   5152802093400064       True  2017-03-08 21:12:07.266040          airplane  \n",
       "1   6577010312740864       True  2017-03-23 02:08:35.229980          airplane  \n",
       "2   5159910851477504       True  2017-03-21 13:02:16.246170       alarm clock  \n",
       "3   4608088873107456       True  2017-03-01 21:42:04.745090       alarm clock  \n",
       "4   5404586804248576       True  2017-01-24 12:58:28.487110         ambulance  \n",
       "5   5731655589298176       True  2017-03-28 15:53:40.978600         ambulance  \n",
       "6   6665588124418048       True  2017-03-03 20:39:08.851890             angel  \n",
       "7   5275268287561728       True  2017-03-05 05:52:48.496610             angel  \n",
       "8   4975017072787456       True  2017-03-22 11:34:53.899460  animal migration  \n",
       "9   4993426342805504       True  2017-03-25 02:43:14.994860  animal migration  \n",
       "10  5421013154136064       True  2017-03-27 00:14:57.310330               ant  \n",
       "11  4836123148812288       True  2017-03-06 20:00:22.521560               ant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualise_data(data_len = 6):\n",
    "    file_names = glob('../input/train_simplified/*.csv')\n",
    "    #column_names = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "    if data_len >= len(file_names) or data_len <= 0:\n",
    "        data_len = 6\n",
    "    \n",
    "    #A list to sample some data\n",
    "    drawlist = []\n",
    "    \n",
    "    for f in file_names[0:data_len]:\n",
    "        data_sample = pd.read_csv(f, nrows = 10)\n",
    "        #apple = data_sample\n",
    "        #keyid = apple.key_id[:2]\n",
    "        #print(keyid)\n",
    "        #drawid=apple.loc[apple['key_id'].isin(keyid)].index.values\n",
    "        #print('hit this',drawid)\n",
    "        data_sample = data_sample[data_sample.recognized==True].head(2)\n",
    "        drawlist.append(data_sample)\n",
    "        column_names = list(data_sample)\n",
    "        #drawing_id = df.loc[df['key_id'].isin(key_id)].index.values\n",
    "        visualise_df = pd.DataFrame(np.concatenate(drawlist), columns=column_names)\n",
    "    \n",
    "    return visualise_df\n",
    "\n",
    "see_data = visualise_data()\n",
    "see_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a84b4be96a668efaa16d3578eafd383bb3c8a1b8"
   },
   "source": [
    "## 1.3.2 Drawing to Image\n",
    "This function will take in data sample one bye one and use the coordinate points to draw out a black and white  image.\n",
    "1. This function takes in drawing points as 'drawing' and dimensions as 'H' and 'W'. Register each stroke base on the time T. And plot it out with cv2.line after the image matrix is 'dotted' with the drawing points\n",
    "2. Activate your data augmentation here, it will automatically rotate the image as and when it likes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0af6064821e7c39d7fbd66560d932552317e9161"
   },
   "outputs": [],
   "source": [
    "def rotateImage(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "def draw_to_image(drawing, H, W):\n",
    "    \n",
    "    data_augment = False\n",
    "    points = []\n",
    "    time = []\n",
    "    #Save all the data from drawing into an array\n",
    "    for t,(x,y) in enumerate(drawing):\n",
    "        points.append(np.array((x,y),np.float32).T)\n",
    "        time.append(np.full(len(x),t))\n",
    "    \n",
    "        \n",
    "    points = np.concatenate(points).astype(np.float32)\n",
    "    time = np.concatenate(time).astype(np.int32)\n",
    "    #print('This is how the points look like \\n', points[:3])\n",
    "    #print('This is how time be like:\\n', time[:3])\n",
    "    #Create the skeleton of an image......................................\n",
    "    image  = np.full((H,W,3),0,np.uint8)\n",
    "    x_max = points[:,0].max()\n",
    "    x_min = points[:,0].min()\n",
    "    y_max = points[:,1].max()\n",
    "    y_min = points[:,1].min()\n",
    "    w = x_max-x_min\n",
    "    h = y_max-y_min\n",
    "    s = max(w,h)\n",
    "    \n",
    "    #Normalise the image\n",
    "    norm_point = (points - [x_min,y_min]) / s  #Remove the empty space around it and shrink it to <=1\n",
    "    norm_point = (norm_point -[w/s*0.5, h/s*0.5]) * max(W,H)*0.85  #Shift the centre of image to become the origin point, then resize it by scaling\n",
    "    norm_point = np.floor(norm_point + [W/2, H/2]).astype(np.int32)  #Shift the smallest point bottom left of image to become the origin point, and also to stretch the image\n",
    "    #..................................................................\n",
    "    \n",
    "    #It basically creates a dot then use cv2.line to draw it... \n",
    "    T = time.max()+1\n",
    "    for t in range (T):\n",
    "        p = norm_point[time==t] #taking one set of [x,y]  which is stack horizontally.\n",
    "        x,y = p.T\n",
    "        image[y,x] = 255\n",
    "        N = len(p)\n",
    "        for i in range(N-1):\n",
    "            x0,y0 = p[i]\n",
    "            x1,y1 = p[i+1]\n",
    "            cv2.line(image,(x0,y0),(x1,y1),(255,255,255),1,cv2.LINE_AA) #Subjected to tunning for temporal\n",
    "    if data_augment:\n",
    "        angle_set = [0, 30, 0, 60, 0, 90, 0, 120, 150, 0 , 180, 0, 210, 0, 240, 0, 270, 0, 300, 0, 330, 360]\n",
    "        angle  = np.random.choice(angle_set,1)\n",
    "        image=rotateImage(image,angle)\n",
    "    return image\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.1 Visualise the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f532d058fc936e22c56dcbff05b0fc0abb2b9986"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_rawdata = (see_data['drawing'])\n",
    "visualise_img=[]\n",
    "for drawing in visualise_rawdata:\n",
    "    drawing =eval(drawing)\n",
    "    img = draw_to_image(drawing,64,64)\n",
    "    \n",
    "    visualise_img.append(img)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44189fb71d48843384310a2ad233f533519a03ff"
   },
   "source": [
    "## 1.3.3 Create a class for data loading in pytorch later\n",
    "[More details can be found here*](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel)\n",
    "In this section it is a function that is called in QuickdrawData for data creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "53b916cc2a627c3845d55184f9946c3bbc1462ec"
   },
   "outputs": [],
   "source": [
    "def create_draw_data(drawing, label, index, key_id, dim = 64):\n",
    "    cache = {'drawing': drawing.copy(), 'label' : label, 'index' : index, 'key_id' : key_id}\n",
    "    #num = random.randint(0,9) #data augmenting\n",
    "    #if (num in [5,9]):\n",
    "    #    dim = 32\n",
    "    #elif (num in [4,8]):\n",
    "    #    dim = 128\n",
    "    #elif (num in [1]):\n",
    "    #    dim = 256\n",
    "    #else:\n",
    "    #    dim = 64\n",
    "    image = draw_to_image(drawing, dim, dim)\n",
    "    return image, label, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0a003bdf13fabea3f2146e67c885ecd646cf765"
   },
   "source": [
    "### 1.3.3.1 Dataset class\n",
    "This will be use for the pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "eb0f8e8d84dd4847fef7e1ba87525cbdb19e29e5"
   },
   "outputs": [],
   "source": [
    "TRAIN_DF = []\n",
    "VALID_DF = []\n",
    "TEST_DF = []\n",
    "class_name = (x[:-4] for x in(os.listdir('../input/train_simplified/')))\n",
    "class_name = sorted(list(class_name))\n",
    "\n",
    "class QuickdrawData(Dataset):\n",
    "\n",
    "    def __init__(self, mode, split='<NIL>', augment = create_draw_data, complexity = 'simplified'):\n",
    "        super(QuickdrawData, self).__init__()\n",
    "        assert complexity in ['simplified', 'raw']\n",
    "        start = timer()\n",
    "\n",
    "        self.split      = split\n",
    "        self.augment    = augment\n",
    "        self.mode       = mode\n",
    "        self.complexity = complexity\n",
    "\n",
    "        self.df  = []\n",
    "        self.id  = []\n",
    "        global TRAIN_DF,TEST_DF,VALID_DF\n",
    "        if mode=='train':\n",
    "            \n",
    "            # countrycode, drawing, key_id, recognized, timestamp, word\n",
    "\n",
    "            if (TRAIN_DF == []) and (split!= 'test_data'):\n",
    "                for l,name in enumerate(class_name):\n",
    "                    print('\\r\\t Now loading df   :  %3d/%3d   %24s   Time taken:%s'%(l,len(class_name),name,time_to_str((timer() - start))),end='',flush=True)\n",
    "                    \n",
    "                    \n",
    "                    #Train data\n",
    "                    df = pd.read_csv('../input/train_%s/%s.csv'%(complexity,name))[50000:95000]\n",
    "                    df = df[df.recognized==True][:30100]\n",
    "                    TRAIN_DF.append(df[:-100])\n",
    "                    #print(len(df[:30000]))\n",
    "                    VALID_DF.append(df[-100:])        \n",
    "                            \n",
    "                    del df\n",
    "                                      \n",
    "                    gc.collect()\n",
    "                    \n",
    "                print('')\n",
    "            self.df = TRAIN_DF\n",
    "            if (split == 'valid_data'):\n",
    "                self.df = VALID_DF\n",
    "\n",
    "            if (TEST_DF == []) and (split == 'test_data'):\n",
    "                for l,name in enumerate(class_name):\n",
    "                    print('\\r\\t Now loading test_df   :  %3d/%3d   %24s   Time taken:%s'%(l,len(class_name),name,time_to_str((timer() - start))),end='',flush=True)\n",
    "\n",
    "                    #Train data\n",
    "                    df = pd.read_csv('../input/train_%s/%s.csv'%(complexity,name))[:70000]\n",
    "                    df = df[df.recognized==True][:40000]\n",
    "                    df = df[30000:]\n",
    "                    TEST_DF.append(df)                         \n",
    "\n",
    "                    del df\n",
    "                    gc.collect()\n",
    "                self.df = TEST_DF\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            for l,name in enumerate(class_name):\n",
    "                print('\\r\\t load %s:  %3d/%3d   %24s   Time taken:%s'%(split,l,len(class_name),name,time_to_str((timer() - start))),end='',flush=True)\n",
    "                if (split=='train_data'):\n",
    "                    df = TRAIN_DF[l]\n",
    "                elif (split=='valid_data'):\n",
    "                    df = VALID_DF[l]\n",
    "                elif (split=='test_data'):\n",
    "                    df = TEST_DF[l]\n",
    "                else:\n",
    "                    raise Exception('Bug in dataset class')\n",
    "                    \n",
    "                key_id = df['key_id'].values.astype(np.int64) #np.load('../data/split/%s/%s.npy'%(split,name))\n",
    "                label = np.full(len(key_id),l,np.int64)\n",
    "                drawing_id = df.loc[df['key_id'].isin(key_id)].index.values\n",
    "                self.id.append(\n",
    "                    np.vstack([label, drawing_id, key_id]).T\n",
    "                )\n",
    "                del key_id,label,drawing_id,df\n",
    "            self.id = np.concatenate(self.id)\n",
    "            print('')\n",
    "\n",
    "        if mode=='test':\n",
    "            #global TEST_DF\n",
    "            # key_id, countrycode, drawing\n",
    "\n",
    "            if TEST_DF == []:\n",
    "#                 TEST_DF = pd.read_csv(DATA_DIR + '/csv/test_%s.csv'%(complexity))\n",
    "                TEST_DF = pd.read_csv('../input/test_%s.csv'%(complexity))\n",
    "                \n",
    "                self.id = np.arange(0,len(TEST_DF))\n",
    "\n",
    "            self.df = TEST_DF\n",
    "\n",
    "        print('')\n",
    "\n",
    "    def __str__(self):\n",
    "        N = len(self.id)\n",
    "        string = ''\\\n",
    "        + '\\tsplit        = %s\\n'%self.split \\\n",
    "        + '\\tmode         = %s\\n'%self.mode \\\n",
    "        + '\\tcomplexity   = %s\\n'%self.complexity \\\n",
    "        + '\\tlen(self.id) = %d\\n'%N \\\n",
    "        + '\\n'\n",
    "        return string\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        if self.mode=='train':\n",
    "            label, drawing_id, key_id = self.id[index]\n",
    "            drawing = self.df[label]['drawing'][drawing_id]\n",
    "            drawing = eval(drawing)\n",
    "\n",
    "        if self.mode=='test':\n",
    "            label=None\n",
    "            drawing = self.df['drawing'][index]\n",
    "            drawing = eval(drawing)\n",
    "            key_id = self.df['key_id'][index]         \n",
    "\n",
    "        return self.augment(drawing, label, index, key_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69000eea7a31ea77c834ba276ff386cc2c6f5984"
   },
   "source": [
    "## 1.4 Downloading of pretrained resnet34 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "13b82c1e8960ccaa7365933afe86dc791697992c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded  ['resnet34-333f7ec4.pth']\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "pretrained_dir = '../pretrained/'\n",
    "os.makedirs(pretrained_dir, exist_ok=True)\n",
    "\n",
    "url = 'https://download.pytorch.org/models/resnet34-333f7ec4.pth'\n",
    "filename = '../pretrained/resnet34-333f7ec4.pth'\n",
    "\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "with urllib.request.urlopen(url) as response, open(filename, 'wb') as out_file:\n",
    "    data = response.read() # a `bytes` object\n",
    "    out_file.write(data)\n",
    "\n",
    "print('Downloaded ',os.listdir(pretrained_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4aa5b5216a742f0f8c7f330e47a6fcc3038cf409"
   },
   "source": [
    "## 1.5 Make ResNet class\n",
    "There is a given resnet model which can be found [here](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py).\n",
    "### 1.5.1 Reference ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b44ca1e678c808cb302bdceac116e69e64be5a4f"
   },
   "outputs": [],
   "source": [
    "BatchNorm2d = nn.BatchNorm2d\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1   = BatchNorm2d(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbfb5df0f57e1adc9159f7a27917135bc12a660e"
   },
   "source": [
    "### 1.5.2 ResNet model for this net\n",
    "This model will utilised the pretrained network for initialising, and it will use some blocks with reference to the 'Reference ResNet Model' above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c78c703b1c3cff0ef11e4951ddcebffad4f9a856"
   },
   "outputs": [],
   "source": [
    "###########################################################################################3\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def load_pretrain(self, pretrain_file):\n",
    "        #raise NotImplementedError\n",
    "        #self.resnet.load_state_dict(torch.load(pretrain_file, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        pretrain_state_dict = torch.load(pretrain_file)\n",
    "        print(\"pretrain_state_dict.keys(): \", pretrain_state_dict.keys())\n",
    "        state_dict = self.state_dict()\n",
    "        print(\"state_dict.keys(): \", state_dict.keys())\n",
    "        keys = list(state_dict.keys())\n",
    "        for key in keys:\n",
    "            if any(s in key for s in []):\n",
    "                continue\n",
    "            if \"num_batches_tracked\" in key:\n",
    "                continue\n",
    "            # if key.startswith('conv1.0'):\n",
    "            #     state_dict[key] = pretrain_state_dict[key.replace('conv1.0','conv1')]\n",
    "            # if key.startswith('conv1.1'):\n",
    "            #     state_dict[key] = pretrain_state_dict[key.replace('conv1.1','bn1')]\n",
    "\n",
    "            # if 'resnet.conv1.' in key:\n",
    "            #     state_dict[key] = pretrain_state_dict[key.replace('resnet.conv1.','conv1.')]\n",
    "            # if 'resnet.bn1.' in key:\n",
    "            #     state_dict[key] = pretrain_state_dict[key.replace('resnet.bn1.','bn1.')]\n",
    "            if 'encoder1.0.' in key:\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('encoder1.0.','conv1.')]\n",
    "                print(key)\n",
    "            if 'encoder1.1.' in key:\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('encoder1.1.','bn1.')]\n",
    "                print(key)\n",
    "\n",
    "            if any(s in key for s in []):\n",
    "                continue\n",
    "            if 'resnet.layer0.' in key:\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('resnet.layer0.','layer0.')]\n",
    "                print(key)\n",
    "            if 'resnet.layer1.' in key:\n",
    "                print('key1: ',key)\n",
    "#                 print('pretrain_state_dict: ',pretrain_state_dict)\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('resnet.layer1.','layer1.')]\n",
    "                print('key2: ',key)\n",
    "            if 'resnet.layer2.' in key:\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('resnet.layer2.','layer2.')]\n",
    "                print(key)\n",
    "            if 'resnet.layer3.' in key:\n",
    "                state_dict[key] = pretrain_state_dict[key.replace('resnet.layer3.','layer3.')]\n",
    "                print(key)\n",
    "            if 'resnet.layer4.' in key:\n",
    "                 state_dict[key] = pretrain_state_dict[key.replace('resnet.layer4.','layer4.')]\n",
    "                 print(key)\n",
    "\n",
    "        self.load_state_dict(state_dict)\n",
    "        print('')\n",
    "\n",
    "\n",
    "    def __init__(self, num_class=340):\n",
    "        super(Net,self).__init__()\n",
    "        self.resnet  = ResNet(BasicBlock, [3, 4, 6, 3],num_classes=1)\n",
    "\n",
    "        # self.conv1 = nn.Sequential(\n",
    "        #     self.resnet.conv1,\n",
    "        #     self.resnet.bn1,\n",
    "        #     self.resnet.relu,\n",
    "        #     #self.resnet.maxpool,\n",
    "        # )\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            self.resnet.layer1,\n",
    "        )\n",
    "        self.encoder3 = self.resnet.layer2\n",
    "        self.encoder4 = self.resnet.layer3\n",
    "        self.encoder5 = self.resnet.layer4\n",
    "        self.logit = nn.Linear(512, num_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "        mean=[0.485, 0.456, 0.406] #rgb\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "        x = torch.cat([\n",
    "            (x[:,[0]]-mean[0])/std[0],\n",
    "            (x[:,[1]]-mean[1])/std[1],\n",
    "            (x[:,[2]]-mean[2])/std[2],\n",
    "        ],1)\n",
    "\n",
    "        x = self.encoder1(x) #; print('e1',x.size())\n",
    "        x = self.encoder2(x) #; print('e2',x.size())\n",
    "        x = self.encoder3(x) #; print('e3',x.size())\n",
    "        x = self.encoder4(x) #; print('e4',x.size())\n",
    "        x = self.encoder5(x) #; print('e5',x.size())\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1).view(batch_size,-1)\n",
    "        x = F.dropout(x, p=0.50, training=self.training)\n",
    "        logit = self.logit(x)\n",
    "\n",
    "        return logit\n",
    "\n",
    "\n",
    "    def set_mode(self, mode, is_freeze_bn=False ):\n",
    "        self.mode = mode\n",
    "        if mode in ['eval', 'valid', 'test']:\n",
    "            self.eval()\n",
    "        elif mode in ['train']:\n",
    "            self.train()\n",
    "            if is_freeze_bn==True: ##freeze\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, BatchNorm2d):\n",
    "                        m.eval()\n",
    "                        m.weight.requires_grad = False\n",
    "                        m.bias.requires_grad   = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "31866a46b8df1dec28e8087a779da857f763439a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************************************************************\n",
      "\n",
      "Net(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (logit): Linear(in_features=512, out_features=340, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print('\\n*****************************************************************************\\n')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "444807ec3ffdf9fce4b759a1b758297e342ceb2f"
   },
   "source": [
    "## 1.6 Miscellaneous Functions\n",
    "This can be considered as the utils package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4d0e531cec23e6ecb79df2c32d008910e1069037"
   },
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_criterion(logit, truth, is_average=True):\n",
    "    loss = F.cross_entropy(logit, truth, reduce=is_average)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def metric(logit, truth, is_average=True):\n",
    "    \"\"\"\n",
    "    -prob: Gives a vertical tensor of probability\n",
    "    -value, top: gives the probability and the top indices\n",
    "    -correct: compare against the ground-truth labels to check if the top 3 categorizing is correct\n",
    "    -correct(under if statement): average out the batch correct prediction\n",
    "    *-avg_prob: comes from the prob but averaged; this is assumed to be sorted according to class label\n",
    "            It is also not compared with the truth\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        prob = F.softmax(logit, 1) #input (m,Num_Class_label); output (m, Num_Class_label)\n",
    "        value, top = prob.topk(3, dim=1, largest=True, sorted=True)\n",
    "        correct = top.eq(truth.view(-1, 1).expand_as(top))\n",
    "\n",
    "        if is_average==True:\n",
    "            # top-3 accuracy\n",
    "            prob_avg = prob.float().sum(0, keepdim=False)\n",
    "            correct = correct.float().sum(0, keepdim=False)\n",
    "            correct = correct/len(truth)\n",
    "\n",
    "            top = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "            precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "            return precision, top, prob_avg\n",
    "\n",
    "        else:\n",
    "            return correct\n",
    "\n",
    "\n",
    "\n",
    "def null_collate(batch):\n",
    "    batch_size = len(batch)\n",
    "    cache = []\n",
    "    input = []\n",
    "    truth = []\n",
    "    for b in range(batch_size):\n",
    "        input.append(batch[b][0])\n",
    "        truth.append(batch[b][1])\n",
    "        cache.append(batch[b][2])\n",
    "        del b\n",
    "\n",
    "    input = np.array(input).transpose(0,3,1,2)\n",
    "    input = torch.from_numpy(input).float()\n",
    "\n",
    "    if truth[0] is not None:\n",
    "        truth = np.array(truth)\n",
    "        truth = torch.from_numpy(truth).long()\n",
    "\n",
    "    return input, truth, cache\n",
    "\n",
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string\n",
    "# https://github.com/pytorch/examples/blob/master/imagenet/main.py ###############\n",
    "def adjust_learning_rate(optimizer, lr, iteration):\n",
    "    lr = 0.2 * lr/(0.01+np.sqrt(iteration/8000))\n",
    "    if (lr<0.0001):\n",
    "        lr = 0.0001\n",
    "    lr = 0.005        \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Main Script\n",
    "## 2.1 Evaluation model and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "16a53e7de9c7405963a4c20c6ff9464b4d76793f"
   },
   "outputs": [],
   "source": [
    "def do_valid( net, valid_generator, criterion ):\n",
    "\n",
    "    valid_num  = 0\n",
    "    probs    = []\n",
    "    valid_labels   = []\n",
    "    losses   = []\n",
    "    corrects = []\n",
    "    truths = []   \n",
    "    \n",
    "    for input, truth, cache  in valid_generator:\n",
    "        \n",
    "        input = input.to(device)\n",
    "        truth = truth.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logit   = net(input)\n",
    "            prob    = F.softmax(logit,1)\n",
    "\n",
    "            loss    = criterion(logit, truth, False)\n",
    "            correct = metric(logit, truth, False)\n",
    "        \n",
    "        valid_num += len(input)\n",
    "        probs.append(prob.data.cpu().numpy())\n",
    "        losses.append(loss.data.cpu().numpy())\n",
    "        corrects.append(correct.data.cpu().numpy())\n",
    "        truths.append(truth.data.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    assert(valid_num == len(valid_generator.sampler))\n",
    "    #------------------------------------------------------\n",
    "    \n",
    "    prob    = np.concatenate(probs)\n",
    "    correct = np.concatenate(corrects)\n",
    "    truth   = np.concatenate(truths).astype(np.int32).reshape(-1,1)\n",
    "    loss    = np.concatenate(losses)\n",
    "\n",
    "\n",
    "    #---\n",
    "    #top = np.argsort(-predict,1)[:,:3]\n",
    "\n",
    "    loss    = loss.mean()\n",
    "    correct = correct.mean(0)\n",
    "\n",
    "    top = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "    precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "\n",
    "    #----\n",
    "    valid_loss = np.array([\n",
    "        loss, top[0], top[2], precision\n",
    "    ])\n",
    "\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "56ec4cf90b778b65106bd3ac538d4ba92216403a"
   },
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    \"\"\"\"\"\n",
    "    This function will utilise the class and functions created above to produce image data and feed\n",
    "    into the gpu for direct trianing by the neural network.\n",
    "    \n",
    "    --------------dataset-------------------\n",
    "    In the creation of this, we will invoke\n",
    "    ->class RandomSampler(Sampler): Samples elements randomly, without replacement.\n",
    "        It can be thought of the order of visiting the image from the training set.\n",
    "    ->nullcollate(): This function will take each batch of data and break them up into 'input, label(truth), cache'\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "     #-----------------Setting up -----------------------------\n",
    "    checkpoint_dir    = '../output/checkpoint'\n",
    "    saved_dir         = '../output/saved'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    pretrain_file_dir = '../pretrained/resnet34-333f7ec4.pth'\n",
    "    load_model_dir    = '../output/checkpoint/Mi00019921_model.pth'\n",
    "    if pretrain_file_dir is not None:\n",
    "        print('\\tpetrained_file_dir = %s\\n'%pretrain_file_dir)\n",
    "    \n",
    "    schduler = NullScheduler(lr=0.001)\n",
    "    criterion = softmax_cross_entropy_criterion\n",
    "    train_loss = np.zeros(6,np.float32)\n",
    "    valid_loss = np.zeros(6,np.float32)\n",
    "    batch_loss = np.zeros(6, np.float32)\n",
    "    #------------------PARAMETERS-------------------------------\n",
    "    \n",
    "    params = {'epochs': 3,\n",
    "             'max_epoch': 100,\n",
    "             'batch_size': 512\n",
    "             }\n",
    "    batch_size = params['batch_size']\n",
    "   #---------------Dataset-------------------------------------\n",
    "    \n",
    "    train_dataset = QuickdrawData('train', 'train_data', create_draw_data)\n",
    "    train_generator_params = {'sampler': RandomSampler(train_dataset),\n",
    "                              'batch_size': params['batch_size'],\n",
    "                              'drop_last': True,\n",
    "                              'num_workers': 0,\n",
    "                              'pin_memory': True,\n",
    "                              'collate_fn': null_collate}\n",
    "    train_generator = DataLoader(train_dataset, **train_generator_params)\n",
    "    \n",
    "    valid_dataset = QuickdrawData('train','valid_data',create_draw_data)\n",
    "    valid_generator_params = {'sampler': RandomSampler(valid_dataset),\n",
    "                              'batch_size': params['batch_size'],\n",
    "                              'drop_last': False,\n",
    "                              'num_workers': 0,\n",
    "                              'pin_memory': True,\n",
    "                              'collate_fn': null_collate}\n",
    "    valid_generator = DataLoader(valid_dataset, **valid_generator_params)\n",
    "        \n",
    "    assert(len(train_dataset)>=params['batch_size'] )\n",
    "    print('batch_size = %d\\n'%(params['batch_size']))\n",
    "    print('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "    print('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "    print('\\n')\n",
    "    \n",
    "    #-----------------net-----------------------------------\n",
    "    print('***net setting***\\n')\n",
    "    net = Net().to(device)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Load model if needed\n",
    "    if load_model_dir is not None:\n",
    "        print('\\tload_model_dir = %s\\n'%load_model_dir)\n",
    "        net.load_state_dict(torch.load(load_model_dir, map_location=lambda storage, loc: storage))\n",
    "    \n",
    "        print('\\tdevice used: ', device, '\\n')\n",
    "    # Confirm is not but just to check\n",
    "    if (pretrain_file_dir is not None) and (load_model_dir is None):\n",
    "        print('\\tpretrain_file_dir = %s\\n'%pretrain_file_dir)\n",
    "        net.load_pretrain(pretrain_file_dir)\n",
    "    \n",
    "    #--------------Optimizer---------------------\n",
    "    \n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                              lr=schduler(0), momentum=0.86, weight_decay=0.0001, nesterov = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-----------Training starts--------------------\n",
    "    iter_validate = 2000\n",
    "    iter_start = 0\n",
    "    iter_train = 100\n",
    "    iter_batch = 1\n",
    "    iter_save = 3007\n",
    "    iteration = 0\n",
    "    i = 0\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Load the previously saved optimizer parameters\n",
    "    if load_model_dir is not None:\n",
    "        initial_optimizer = load_model_dir.replace('_model.pth', '_optimizer.pth')\n",
    "        checkpoint = torch.load(initial_optimizer)\n",
    "        iteration  = checkpoint['iteration']\n",
    "        epoch      = checkpoint['epoch'] \n",
    "        iter_batch = checkpoint['iter_batch']\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print('\\tinitial_optimizer: ',initial_optimizer, '\\n')\n",
    "    \n",
    "    print('*****Training now... *****\\n')\n",
    "    print('                                 ||--------------Validation------------------||----------------Batch----------------------         \\n')\n",
    "    print('time    lr    epoch    batch No. ||  loss   acc-1   acc-2(All top 3)   lb    ||  loss   acc-1   acc-2(All top 3)   lb|             \\n ')\n",
    "    print('--------------------------------------------------------------------------------------------------------------------------         \\n')\n",
    "    start= timer()\n",
    "    for epoch in range(params['epochs']):\n",
    "        sum = 0\n",
    "        sum_train_loss = np.zeros(6,np.float32)\n",
    "        iter_batch = 0\n",
    "        torch.save(net, checkpoint_dir+'/%08d_model.pth'%(epoch))\n",
    "                \n",
    "        \n",
    "        #Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Iteration over mini-batches in one epoch########################################\n",
    "        for input, train_labels, cache in train_generator: \n",
    "            \n",
    "            iteration = i + iter_start\n",
    "            minibatch_len = len(train_generator)\n",
    "            batch_size = len(cache)\n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            #----------Checkpoint save----------\n",
    "            if (iter_batch%2000==0):\n",
    "                \n",
    "                torch.save(net.state_dict(), checkpoint_dir+'/%08d_model.pth'%(iteration))\n",
    "                torch.save({\n",
    "                        'optimizer'   : optimizer.state_dict(),\n",
    "                        'iteration'   : i,\n",
    "                        'iter_batch'  : iter_batch,\n",
    "                        'epoch'       : epoch,\n",
    "                }, checkpoint_dir+'/%08d_optimizer.pth'%(iteration))\n",
    "            \n",
    "            \n",
    "            #----------learning rate----------\n",
    "            lr = schduler(iteration)\n",
    "            if lr<0 : break\n",
    "            adjust_learning_rate(optimizer, lr, iteration)\n",
    "            rate = get_learning_rate(optimizer)\n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "            #----------Feed and train one mini-batch----------\n",
    "            #Removes BatchNorm instances parameters from requires_grad\n",
    "            net.set_mode('train')\n",
    "            #Send input and labels to gpu\n",
    "            input = input.to(device)\n",
    "            train_labels = train_labels.to(device)\n",
    "            \n",
    "            #input.requires_grad is not required as we have initiate this when we start??\n",
    "            \n",
    "            #Forward the mini-batch through the net\n",
    "                #scores = data_parallel(net,input)  #This function is similar to input(net), but for multiple gpu\n",
    "            scores = net(input)\n",
    "            \n",
    "            #Compute the average of the losses of the data points in the mini-batch\n",
    "            loss = criterion(scores, train_labels)\n",
    "            precision, top_prediction, prob_avg = metric(scores,train_labels)\n",
    "            \n",
    "            #Backward pass to compute dL/dU, dL/dW, and dL,dV\n",
    "            loss.backward()\n",
    "            \n",
    "            #Do one step of stochastic gradient descent\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            i+=1\n",
    "            iter_batch += 1\n",
    "            #COMPUTE THE STATISTICS\n",
    "            batch_loss[:4] = np.array(( loss.item(), top_prediction[0].item(), top_prediction[2].item(), precision.item(),))\n",
    "            #one epoch is too long, use this to probe hows the avg loss of the training dat is performing; every 20 times\n",
    "            sum_train_loss += batch_loss\n",
    "            sum+=1\n",
    "            if (iteration%iter_train==0) :\n",
    "                train_loss = sum_train_loss/sum\n",
    "                sum_train_loss = np.zeros(6,np.float32)\n",
    "                sum = 0\n",
    "                \n",
    "            \n",
    "            \n",
    "            #print('*****Training now... *****\\n')\n",
    "            #print('                                 ||--------------Validation------------------||----------------Batch----------------------         \\n')\n",
    "            #print('time    lr    epoch    batch No. ||  loss   acc-1   acc-2(All top 3)   lb    ||  loss   acc-1   acc-2(All top 3)   lb|             \\n ')\n",
    "            #print('--------------------------------------------------------------------------------------------------------------------------         \\n')\n",
    "            if (iter_batch%5==0): \n",
    "                print('\\r' ,end='' ,flush = True)\n",
    "                #print('%s    %0.4f   %0.1f  %0.1f/%0.1f ||  %0.3f   %0.3f   %0.3f   (%0.3)   ||   %0.3f   %0.3f   %0.3f   (%0.3) |' % (\\\n",
    "                 #   time_to_str((timer() - start),'min'),rate,epoch,iter_batch,train_dataset_len,\n",
    "                 #   valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3], batch_loss[0], batch_loss[1], batch_loss[2], batch_loss[3]),end='',  flush=True)\n",
    "                print('%s    %0.4f   %d  %d/%d || %0.3f  %0.3f  %0.3f  (%0.3f)%s  || %0.3f  %0.3f  %0.3f  (%0.3f)  | ' % (\\\n",
    "                         time_to_str((timer() - start),'min'),rate,(1+epoch),iter_batch,minibatch_len,\n",
    "                         valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3],' ',\n",
    "                         batch_loss[0], batch_loss[1], batch_loss[2], batch_loss[3])\n",
    "            , end='',flush=True)\n",
    "            #Conduct validation on each 100 iterations, regardless of epoch\n",
    "            if (iteration % iter_validate==0 ) and (iter!=0):\n",
    "                net.set_mode('valid')\n",
    "                valid_loss = do_valid(net, valid_generator, criterion)\n",
    "                net.set_mode('train')\n",
    "                elapsed = time_to_str((timer() - start),'min')\n",
    "                print('\\n\\r',end='',flush=True)\n",
    "                print('=========================================\\n')\n",
    "                print('Time:',elapsed,'\\t epoch:',(epoch+1+start_epoch),'\\t lr:',rate,'\\t train loss:',train_loss[0],'\\n\\t train accuracy:',\n",
    "                train_loss[3],'\\t valid accuracy:',valid_loss[3], '\\titerations: ',iteration)\n",
    "                print('=========================================\\n')\n",
    "                \n",
    "                print('')\n",
    "            del input,train_labels,cache\n",
    "        \n",
    "        \n",
    "    if 1: #Save last\n",
    "        torch.save(net.state_dict(),saved_dir+'/%d_model.pth'%(i))\n",
    "        torch.save({\n",
    "            'optimizer'   : optimizer.state_dict(),\n",
    "            'iteration'   : i,\n",
    "            'iter_batch'  : iter_batch, \n",
    "            'epoch'       : epoch,\n",
    "        }, saved_dir+'/%d_optimizer.pth'%(i))\n",
    "        torch.save(net, checkpoint_dir+'/END_model.pth')\n",
    "    \n",
    "    print('\\n\\t\\t****************************************\\n\\n')\n",
    "    print('\\t\\t**************************************************\\n\\n')\n",
    "    print('\\t\\t\\t\\tEND OF TRAINING!\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0072a6f8a2e4bbaed38edc686a40b4c95a7664c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tpetrained_file_dir = ../pretrained/resnet34-333f7ec4.pth\n",
      "\n",
      "\t Now loading df   :  339/340                     zigzag   Time taken: 0 hr 05 min\n",
      "\t load train_data:  339/340                     zigzag   Time taken: 0 hr 05 min\n",
      "\n",
      "\t load valid_data:  339/340                     zigzag   Time taken: 0 hr 00 min\n",
      "\n",
      "batch_size = 512\n",
      "\n",
      "train_dataset : \n",
      "\tsplit        = train_data\n",
      "\tmode         = train\n",
      "\tcomplexity   = simplified\n",
      "\tlen(self.id) = 10200000\n",
      "\n",
      "\n",
      "\n",
      "valid_dataset : \n",
      "\tsplit        = valid_data\n",
      "\tmode         = train\n",
      "\tcomplexity   = simplified\n",
      "\tlen(self.id) = 34000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "***net setting***\n",
      "\n",
      "\tload_model_dir = ../output/checkpoint/Mi00019921_model.pth\n",
      "\n",
      "\tdevice used:  cuda \n",
      "\n",
      "\tinitial_optimizer:  ../output/checkpoint/Mi00019921_optimizer.pth \n",
      "\n",
      "*****Training now... *****\n",
      "\n",
      "                                 ||--------------Validation------------------||----------------Batch----------------------         \n",
      "\n",
      "time    lr    epoch    batch No. ||  loss   acc-1   acc-2(All top 3)   lb    ||  loss   acc-1   acc-2(All top 3)   lb|             \n",
      " \n",
      "--------------------------------------------------------------------------------------------------------------------------         \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Wachn\\Miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "D:\\Users\\Wachn\\Miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "D:\\Users\\Wachn\\Miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "D:\\Users\\Wachn\\Miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "D:\\Users\\Wachn\\Miniconda3\\envs\\deeplearn_course\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "\n",
      "Time:  0 hr 00 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.66382587 \n",
      "\t train accuracy: 0.90234375 \t valid accuracy: 0.898843137254902 \titerations:  0\n",
      "=========================================\n",
      "\n",
      "\n",
      " 0 hr 29 min    0.0050   1  2000/19921 || 0.508  0.846  0.961  (0.899)   || 0.493  0.850  0.967  (0.903)  | \n",
      "=========================================\n",
      "\n",
      "Time:  0 hr 30 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.5684516 \n",
      "\t train accuracy: 0.88853204 \t valid accuracy: 0.8932107843137255 \titerations:  2000\n",
      "=========================================\n",
      "\n",
      "\n",
      " 0 hr 58 min    0.0050   1  4000/19921 || 0.536  0.837  0.958  (0.893)   || 0.493  0.865  0.955  (0.908)  | \n",
      "=========================================\n",
      "\n",
      "Time:  0 hr 59 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.55929357 \n",
      "\t train accuracy: 0.8909571 \t valid accuracy: 0.8931127450980392 \titerations:  4000\n",
      "=========================================\n",
      "\n",
      "\n",
      " 1 hr 28 min    0.0050   1  6000/19921 || 0.533  0.837  0.959  (0.893)   || 0.529  0.857  0.973  (0.911)  | \n",
      "=========================================\n",
      "\n",
      "Time:  1 hr 29 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.57080096 \n",
      "\t train accuracy: 0.88857436 \t valid accuracy: 0.8947794117647059 \titerations:  6000\n",
      "=========================================\n",
      "\n",
      "\n",
      " 1 hr 57 min    0.0050   1  8000/19921 || 0.529  0.840  0.959  (0.895)   || 0.712  0.803  0.939  (0.865)  | \n",
      "=========================================\n",
      "\n",
      "Time:  1 hr 58 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.5728358 \n",
      "\t train accuracy: 0.88755876 \t valid accuracy: 0.8944950980392157 \titerations:  8000\n",
      "=========================================\n",
      "\n",
      "\n",
      " 2 hr 26 min    0.0050   1  10000/19921 || 0.528  0.840  0.959  (0.894)   || 0.517  0.846  0.961  (0.899)  | \n",
      "=========================================\n",
      "\n",
      "Time:  2 hr 27 min \t epoch: 1 \t lr: 0.005 \t train loss: 0.56276125 \n",
      "\t train accuracy: 0.89068013 \t valid accuracy: 0.8949166666666667 \titerations:  10000\n",
      "=========================================\n",
      "\n",
      "\n",
      " 2 hr 28 min    0.0050   1  10080/19921 || 0.527  0.840  0.959  (0.895)   || 0.536  0.844  0.955  (0.895)  | "
     ]
    }
   ],
   "source": [
    "run_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Test\n",
    "## 3.1 Test inference - Output \n",
    "This will output the required csv file for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f0b9578b82313c39f03535475bcb70d69d14399"
   },
   "outputs": [],
   "source": [
    "def run_test():\n",
    "\n",
    "    #---------setup----------\n",
    "    manual_check = 3\n",
    "    load_model_dir = '../output/checkpoint/Mi00019921_model.pth'\n",
    "    batch_size = 256\n",
    "    class_name = (x[:-4] for x in(os.listdir('../input/train_simplified/')))\n",
    "    class_name = sorted(list(class_name))\n",
    "    csv_file = '../output/test_csv/%d_prediction_linc.csv'%(manual_check)\n",
    "    os.makedirs('../output/test_csv/', exist_ok=True)\n",
    "    #----------dataset----------\n",
    "    mode = 'train'\n",
    "\n",
    "    test_dataset = QuickdrawData(mode, 'test_data', create_draw_data)\n",
    "    test_generator_params = {'sampler': SequentialSampler(test_dataset),\n",
    "                              'batch_size': batch_size,\n",
    "                              'drop_last': False,\n",
    "                              'num_workers': 0,\n",
    "                              'pin_memory': True,\n",
    "                              'collate_fn': null_collate}\n",
    "    test_generator = DataLoader(test_dataset, **test_generator_params)\n",
    "    assert(len(test_dataset)>=batch_size)\n",
    "    print('test_datset : \\n%s\\n'%(test_dataset))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    #----------net----------\n",
    "    print('***net setting***\\n')\n",
    "    net = Net().to(device)\n",
    "    print('%s\\n\\n'%(type(net)))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "    # Load model if needed\n",
    "    if load_model_dir is not None:\n",
    "        print('\\tload_model_dir = %s\\n'%load_model_dir)\n",
    "        net.load_state_dict(torch.load(load_model_dir, map_location=lambda storage, loc: storage))\n",
    "    # Confirm is not but just to check\n",
    "    #if (pretrain_file_dir is not None) and (load_model_dir is None):\n",
    "        #print('\\tpretrain_file_dir = %s\\n'%pretrain_file_dir)\n",
    "        #net.load_pretrain(pretrain_file_dir)\n",
    "\n",
    "\n",
    "    #----------Start Test----------\n",
    "    criterion = softmax_cross_entropy_criterion\n",
    "    test_num  = 0\n",
    "    probs    = []\n",
    "    top_positions = []\n",
    "    key_id = []\n",
    "    key_ids = []\n",
    "    iter_batch = 0\n",
    "    #test_labels   = []\n",
    "    #losses   = []\n",
    "    #corrects = []\n",
    "    if 1:\n",
    "        print('*****Testing now... *****\\n')\n",
    "        print('                  ||--------------Test Result------------------| \\n')\n",
    "        print('time    batch No. ||  loss   acc-1   acc-2(All top 3)   lb    |  \\n ')\n",
    "        print('--------------------------------------------------------------------------------------------------------     \\n')\n",
    "    net.set_mode('test')\n",
    "    start = timer()\n",
    "    for input, test_label, cache in tqdm_notebook(test_generator, desc='Testing'):\n",
    "\n",
    "        print('\\r\\t',test_num, end='',flush=True)\n",
    "        test_num += len(test_label)\n",
    "        iter_batch+=1\n",
    "        iter_size = len(test_generator)\n",
    "        input = input.to(device)\n",
    "        test_label = test_label.to(device)  #Comment off if 'mode = test'\n",
    "        for key_cache in cache:\n",
    "            key_ids.append(key_cache['key_id'])\n",
    "        \n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logit = net(input)\n",
    "            prob = F.softmax(logit,1) #input (m,Num_Class_label); output (m, Num_Class_label)\n",
    "            loss = criterion(logit, test_label,False)\n",
    "            #probs.append(prob.data.cpu().numpy())  #Send probabilities to cpu\n",
    "\n",
    "            value, top_position = prob.topk(10, dim=1, largest=True, sorted=True)\n",
    "            value = value.view(-1,10)\n",
    "            #top_position = value.view(-1,10)\n",
    "            probs.append(value.data.cpu().numpy())  #Send probabilities to cpu\n",
    "            top_positions.append(top_position.data.cpu().numpy())\n",
    "            \n",
    "            if 0 and (iter_batch in [1,276,388]):\n",
    "                counter = 0\n",
    "                #sample_len = len(test_label)\n",
    "                for single_cache in cache[:8]:\n",
    "                    #draw 5 out\n",
    "                    drawing = single_cache['drawing']\n",
    "                    if counter<5:\n",
    "                        #drawing = eval(drawing)\n",
    "                        img = draw_to_image(drawing, 128, 128)\n",
    "                        plt.imshow(img)\n",
    "                        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "                        plt.show()\n",
    "                        print('\\nThis is the key_id: ', single_cache['key_id'], ' the predicted labels:',top_position,\n",
    "                             'true label: ', class_name[single_cache['label']],'\\n')\n",
    "                        counter+=1\n",
    "\n",
    "\n",
    "            if 1:\n",
    "                correct = top_position.eq(test_label.view(-1, 1).expand_as(top_position)) #Get out the one-hot vector for each row\n",
    "                # top-3 accuracy for a single batch of test\n",
    "                #prob_avg = prob.float().sum(0, keepdim=False)\n",
    "                avg_loss = loss.float().sum(0, keepdim=False)\n",
    "                avg_loss = avg_loss.item()\n",
    "                \n",
    "                correct = correct.float().sum(0, keepdim=False)\n",
    "                correct = correct/len(test_label)\n",
    "\n",
    "                top_acc = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "                precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "            \n",
    "\n",
    "                test_loss = np.array(( avg_loss, top_acc[0].item(), top_acc[2].item(), precision.item(),))\n",
    "\n",
    "                if (iter_batch%5==0): \n",
    "                    print('\\r' ,end='' ,flush = True)\n",
    "                    #print('%s    %0.4f   %0.1f  %0.1f/%0.1f ||  %0.3f   %0.3f   %0.3f   (%0.3)   ||   %0.3f   %0.3f   %0.3f   (%0.3) |' % (\\\n",
    "                     #   time_to_str((timer() - start),'min'),rate,epoch,iter_batch,train_dataset_len,\n",
    "                     #   valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3], batch_loss[0], batch_loss[1], batch_loss[2], batch_loss[3]),end='',  flush=True)\n",
    "                    print('%s    %d/%d || %0.3f  %0.3f  %0.3f  (%0.3f)%s  ||' % (\\\n",
    "                             time_to_str((timer() - start),'min'),iter_batch,iter_size,\n",
    "                             test_loss[0], test_loss[1], test_loss[2], test_loss[3],' ',))\n",
    "    #key_ids = np.concatenate(key_ids)\n",
    "    key_ids = np.reshape(key_ids,(-1,1))\n",
    "    probs = np.concatenate(probs)\n",
    "    \n",
    "    top_positions = np.concatenate(top_positions)\n",
    "    assert(test_num == len(test_generator.sampler))\n",
    "    print('\\r\\t',test_num, end='\\n', flush=True)\n",
    "    print('\\nThis is key_ids: ', key_ids.shape)\n",
    "    print('\\nTHis is probs:', probs.shape)\n",
    "    #print(probs[0])\n",
    "    \n",
    "    print('\\nThis is top_positions: ',top_positions.shape) \n",
    "    df = pd.DataFrame({'key_id': key_ids.tolist(), 'scores': probs.tolist(), 'labels': top_positions.tolist()}).astype(str)\n",
    "    df.to_csv(csv_file, mode='a', header=False, index=False, columns=['key_id', 'scores','labels'], compression='')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6912fdb06d097d1721f93f865c0ff18859c72f01"
   },
   "outputs": [],
   "source": [
    "#dff = run_test()\n",
    "#dff.head(5)\n",
    "#del test_dataset, test_generator\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(validation_linc[0].iloc[0])\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
