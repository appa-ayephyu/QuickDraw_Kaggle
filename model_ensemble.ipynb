{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['valid_simplified.csv', 'train_simplified', 'test_simplified.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python36.zip', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/lib-dynload', '/home/cheeseprata/.local/lib/python3.6/site-packages', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg', '/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/extensions', '/home/cheeseprata/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2050ec8afafd75135ee48f1da6e4fbf05fee8242"
   },
   "outputs": [],
   "source": [
    "CSV_DATA_DIR = \"../input\"\n",
    "NPY_DATA_DIR = '../data'\n",
    "\n",
    "# CLASS_NAME = ['apple','bee', 'cat', 'fish', 'frog', 'leaf']\n",
    "\n",
    "CLASS_NAME=\\\n",
    "['The_Eiffel_Tower', 'The_Great_Wall_of_China', 'The_Mona_Lisa', 'airplane', 'alarm_clock', 'ambulance', 'angel',\n",
    " 'animal_migration', 'ant', 'anvil', 'apple', 'arm', 'asparagus', 'axe', 'backpack', 'banana', 'bandage', 'barn',\n",
    " 'baseball', 'baseball_bat', 'basket', 'basketball', 'bat', 'bathtub', 'beach', 'bear', 'beard', 'bed', 'bee',\n",
    " 'belt', 'bench', 'bicycle', 'binoculars', 'bird', 'birthday_cake', 'blackberry', 'blueberry', 'book',\n",
    " 'boomerang', 'bottlecap', 'bowtie', 'bracelet', 'brain', 'bread', 'bridge', 'broccoli', 'broom',\n",
    " 'bucket', 'bulldozer', 'bus', 'bush', 'butterfly', 'cactus', 'cake', 'calculator', 'calendar', 'camel',\n",
    " 'camera', 'camouflage', 'campfire', 'candle', 'cannon', 'canoe', 'car', 'carrot', 'castle', 'cat', 'ceiling_fan',\n",
    " 'cell_phone', 'cello', 'chair', 'chandelier', 'church', 'circle', 'clarinet', 'clock', 'cloud', 'coffee_cup',\n",
    " 'compass', 'computer', 'cookie', 'cooler', 'couch', 'cow', 'crab', 'crayon', 'crocodile', 'crown', 'cruise_ship',\n",
    " 'cup', 'diamond', 'dishwasher', 'diving_board', 'dog', 'dolphin', 'donut', 'door', 'dragon', 'dresser',\n",
    " 'drill', 'drums', 'duck', 'dumbbell', 'ear', 'elbow', 'elephant', 'envelope', 'eraser', 'eye', 'eyeglasses',\n",
    " 'face', 'fan', 'feather', 'fence', 'finger', 'fire_hydrant', 'fireplace', 'firetruck', 'fish', 'flamingo',\n",
    " 'flashlight', 'flip_flops', 'floor_lamp', 'flower', 'flying_saucer', 'foot', 'fork', 'frog', 'frying_pan',\n",
    " 'garden', 'garden_hose', 'giraffe', 'goatee', 'golf_club', 'grapes', 'grass', 'guitar', 'hamburger',\n",
    " 'hammer', 'hand', 'harp', 'hat', 'headphones', 'hedgehog', 'helicopter', 'helmet', 'hexagon', 'hockey_puck',\n",
    " 'hockey_stick', 'horse', 'hospital', 'hot_air_balloon', 'hot_dog', 'hot_tub', 'hourglass', 'house', 'house_plant',\n",
    " 'hurricane', 'ice_cream', 'jacket', 'jail', 'kangaroo', 'key', 'keyboard', 'knee', 'ladder', 'lantern', 'laptop',\n",
    " 'leaf', 'leg', 'light_bulb', 'lighthouse', 'lightning', 'line', 'lion', 'lipstick', 'lobster', 'lollipop', 'mailbox',\n",
    " 'map', 'marker', 'matches', 'megaphone', 'mermaid', 'microphone', 'microwave', 'monkey', 'moon', 'mosquito',\n",
    " 'motorbike', 'mountain', 'mouse', 'moustache', 'mouth', 'mug', 'mushroom', 'nail', 'necklace', 'nose', 'ocean',\n",
    " 'octagon', 'octopus', 'onion', 'oven', 'owl', 'paint_can', 'paintbrush', 'palm_tree', 'panda', 'pants',\n",
    " 'paper_clip', 'parachute', 'parrot', 'passport', 'peanut', 'pear', 'peas', 'pencil', 'penguin', 'piano',\n",
    " 'pickup_truck', 'picture_frame', 'pig', 'pillow', 'pineapple', 'pizza', 'pliers', 'police_car', 'pond',\n",
    " 'pool', 'popsicle', 'postcard', 'potato', 'power_outlet', 'purse', 'rabbit', 'raccoon', 'radio', 'rain',\n",
    " 'rainbow', 'rake', 'remote_control', 'rhinoceros', 'river', 'roller_coaster', 'rollerskates', 'sailboat',\n",
    " 'sandwich', 'saw', 'saxophone', 'school_bus', 'scissors', 'scorpion', 'screwdriver', 'sea_turtle', 'see_saw',\n",
    " 'shark', 'sheep', 'shoe', 'shorts', 'shovel', 'sink', 'skateboard', 'skull', 'skyscraper', 'sleeping_bag',\n",
    " 'smiley_face', 'snail', 'snake', 'snorkel', 'snowflake', 'snowman', 'soccer_ball', 'sock', 'speedboat',\n",
    " 'spider', 'spoon', 'spreadsheet', 'square', 'squiggle', 'squirrel', 'stairs', 'star', 'steak', 'stereo',\n",
    " 'stethoscope', 'stitches', 'stop_sign', 'stove', 'strawberry', 'streetlight', 'string_bean', 'submarine',\n",
    " 'suitcase', 'sun', 'swan', 'sweater', 'swing_set', 'sword', 't-shirt', 'table', 'teapot', 'teddy-bear',\n",
    " 'telephone', 'television', 'tennis_racquet', 'tent', 'tiger', 'toaster', 'toe', 'toilet', 'tooth',\n",
    " 'toothbrush', 'toothpaste', 'tornado', 'tractor', 'traffic_light', 'train', 'tree', 'triangle',\n",
    " 'trombone', 'truck', 'trumpet', 'umbrella', 'underwear', 'van', 'vase', 'violin', 'washing_machine',\n",
    " 'watermelon', 'waterslide', 'whale', 'wheel', 'windmill', 'wine_bottle', 'wine_glass', 'wristwatch',\n",
    " 'yoga', 'zebra', 'zigzag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b4ee3f15ec1282a9aca02990d198bb5f7fa86834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TkAgg\n",
      "\tset random seed\n",
      "\t\tSEED=35202\n",
      "\tset cuda environment\n",
      "\t\ttorch.__version__              = 0.4.1.post2\n",
      "\t\ttorch.version.cuda             = 9.0.176\n",
      "\t\ttorch.backends.cudnn.version() = 7102\n",
      "\t\tos['CUDA_VISIBLE_DEVICES']     = None\n",
      "\t\ttorch.cuda.device_count()      = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import in common.py\n",
    "import os\n",
    "from datetime import datetime\n",
    "PROJECT_PATH = os.path.dirname('./')\n",
    "IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "\n",
    "#numerical libs\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "#matplotlib.use('WXAgg')\n",
    "#matplotlib.use('Qt4Agg')\n",
    "#matplotlib.use('Qt5Agg') #Qt4Agg\n",
    "print(matplotlib.get_backend())\n",
    "#print(matplotlib.__version__)\n",
    "\n",
    "\n",
    "# torch libs\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# std libs\n",
    "import collections\n",
    "import copy\n",
    "import numbers\n",
    "import inspect\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import sys\n",
    "from distutils.dir_util import copy_tree\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from skimage.transform import resize as skimage_resize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constant #\n",
    "PI  = np.pi\n",
    "INF = np.inf\n",
    "EPS = 1e-12\n",
    "\n",
    "\n",
    "# common.py\n",
    "\n",
    "class Struct(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# print('@%s:  ' % os.path.basename(__file__))\n",
    "\n",
    "if 1:\n",
    "    SEED = 35202  #123  #int(time.time()) #\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    print ('\\tset random seed')\n",
    "    print ('\\t\\tSEED=%d'%SEED)\n",
    "\n",
    "if 1:\n",
    "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = True\n",
    "    print ('\\tset cuda environment')\n",
    "    print ('\\t\\ttorch.__version__              =', torch.__version__)\n",
    "    print ('\\t\\ttorch.version.cuda             =', torch.version.cuda)\n",
    "    print ('\\t\\ttorch.backends.cudnn.version() =', torch.backends.cudnn.version())\n",
    "    try:\n",
    "        print ('\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     =',os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "        NUM_CUDA_DEVICES = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\n",
    "    except Exception:\n",
    "        print ('\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     =','None')\n",
    "        NUM_CUDA_DEVICES = 1\n",
    "\n",
    "    print ('\\t\\ttorch.cuda.device_count()      =', torch.cuda.device_count())\n",
    "    #print ('\\t\\ttorch.cuda.current_device()    =', torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_aye = ['key_id','probabilities_aye','class_id_aye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5054234925989888</td>\n",
       "      <td>[0.9982976317405701, 0.00025638070655986667, 0...</td>\n",
       "      <td>[0, 217, 308, 30, 81, 165, 58, 85, 38, 206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5754535014301696</td>\n",
       "      <td>[0.9981287121772766, 0.0008819419308565557, 0....</td>\n",
       "      <td>[0, 306, 44, 190, 286, 297, 319, 244, 330, 165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6010760482258944</td>\n",
       "      <td>[0.6661585569381714, 0.2732973098754883, 0.014...</td>\n",
       "      <td>[270, 225, 58, 74, 337, 0, 81, 55, 254, 319]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6677025135788032</td>\n",
       "      <td>[0.3110988140106201, 0.24152500927448273, 0.19...</td>\n",
       "      <td>[243, 226, 0, 1, 130, 251, 161, 279, 131, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5017604076863488</td>\n",
       "      <td>[0.9166284799575806, 0.027700455859303474, 0.0...</td>\n",
       "      <td>[0, 30, 145, 124, 319, 17, 70, 206, 71, 219]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  probabilities_aye  \\\n",
       "0  5054234925989888  [0.9982976317405701, 0.00025638070655986667, 0...   \n",
       "1  5754535014301696  [0.9981287121772766, 0.0008819419308565557, 0....   \n",
       "2  6010760482258944  [0.6661585569381714, 0.2732973098754883, 0.014...   \n",
       "3  6677025135788032  [0.3110988140106201, 0.24152500927448273, 0.19...   \n",
       "4  5017604076863488  [0.9166284799575806, 0.027700455859303474, 0.0...   \n",
       "\n",
       "                                      class_id_aye  \n",
       "0      [0, 217, 308, 30, 81, 165, 58, 85, 38, 206]  \n",
       "1  [0, 306, 44, 190, 286, 297, 319, 244, 330, 165]  \n",
       "2     [270, 225, 58, 74, 337, 0, 81, 55, 254, 319]  \n",
       "3   [243, 226, 0, 1, 130, 251, 161, 279, 131, 114]  \n",
       "4     [0, 30, 145, 124, 319, 17, 70, 206, 71, 219]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aye = pd.read_csv('../validation_aye.csv', header=None, names=column_names_aye)\n",
    "df_aye.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399660"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_linc = ['key_id','probabilities_linc','class_id_linc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5054234925989888]</td>\n",
       "      <td>[1.0, 3.544855381454326e-11, 2.811725505202922...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 171, 70, 74, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5754535014301696]</td>\n",
       "      <td>[1.0, 2.777928109765071e-08, 1.150913586656088...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 190, 74, 171, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6010760482258944]</td>\n",
       "      <td>[0.9997758269309998, 0.00015856364916544408, 3...</td>\n",
       "      <td>[0, 306, 225, 319, 337, 166, 171, 59, 282, 264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6677025135788032]</td>\n",
       "      <td>[0.9987855553627014, 0.0010346819180995226, 6....</td>\n",
       "      <td>[0, 240, 264, 226, 126, 114, 46, 131, 116, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5017604076863488]</td>\n",
       "      <td>[1.0, 1.7897846538161843e-09, 1.20063547992543...</td>\n",
       "      <td>[0, 306, 44, 70, 165, 171, 72, 264, 226, 240]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               key_id                                 probabilities_linc  \\\n",
       "0  [5054234925989888]  [1.0, 3.544855381454326e-11, 2.811725505202922...   \n",
       "1  [5754535014301696]  [1.0, 2.777928109765071e-08, 1.150913586656088...   \n",
       "2  [6010760482258944]  [0.9997758269309998, 0.00015856364916544408, 3...   \n",
       "3  [6677025135788032]  [0.9987855553627014, 0.0010346819180995226, 6....   \n",
       "4  [5017604076863488]  [1.0, 1.7897846538161843e-09, 1.20063547992543...   \n",
       "\n",
       "                                     class_id_linc  \n",
       "0    [0, 165, 306, 226, 264, 171, 70, 74, 240, 46]  \n",
       "1   [0, 165, 306, 226, 264, 190, 74, 171, 240, 46]  \n",
       "2  [0, 306, 225, 319, 337, 166, 171, 59, 282, 264]  \n",
       "3   [0, 240, 264, 226, 126, 114, 46, 131, 116, 72]  \n",
       "4    [0, 306, 44, 70, 165, 171, 72, 264, 226, 240]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linc = pd.read_csv('../validation_linc.csv', header=None, names=column_names_linc)\n",
    "df_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linc['key_id'] = df_linc['key_id'].apply(lambda x: int(x[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5054234925989888</td>\n",
       "      <td>[1.0, 3.544855381454326e-11, 2.811725505202922...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 171, 70, 74, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5754535014301696</td>\n",
       "      <td>[1.0, 2.777928109765071e-08, 1.150913586656088...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 190, 74, 171, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6010760482258944</td>\n",
       "      <td>[0.9997758269309998, 0.00015856364916544408, 3...</td>\n",
       "      <td>[0, 306, 225, 319, 337, 166, 171, 59, 282, 264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6677025135788032</td>\n",
       "      <td>[0.9987855553627014, 0.0010346819180995226, 6....</td>\n",
       "      <td>[0, 240, 264, 226, 126, 114, 46, 131, 116, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5017604076863488</td>\n",
       "      <td>[1.0, 1.7897846538161843e-09, 1.20063547992543...</td>\n",
       "      <td>[0, 306, 44, 70, 165, 171, 72, 264, 226, 240]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_linc  \\\n",
       "0  5054234925989888  [1.0, 3.544855381454326e-11, 2.811725505202922...   \n",
       "1  5754535014301696  [1.0, 2.777928109765071e-08, 1.150913586656088...   \n",
       "2  6010760482258944  [0.9997758269309998, 0.00015856364916544408, 3...   \n",
       "3  6677025135788032  [0.9987855553627014, 0.0010346819180995226, 6....   \n",
       "4  5017604076863488  [1.0, 1.7897846538161843e-09, 1.20063547992543...   \n",
       "\n",
       "                                     class_id_linc  \n",
       "0    [0, 165, 306, 226, 264, 171, 70, 74, 240, 46]  \n",
       "1   [0, 165, 306, 226, 264, 190, 74, 171, 240, 46]  \n",
       "2  [0, 306, 225, 319, 337, 166, 171, 59, 282, 264]  \n",
       "3   [0, 240, 264, 226, 126, 114, 46, 131, 116, 72]  \n",
       "4    [0, 306, 44, 70, 165, 171, 72, 264, 226, 240]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_linc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_elmo = ['key_id','probabilities_elmo','class_id_elmo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5061933910720512</td>\n",
       "      <td>[0.34392818808555603, 0.29753392934799194, 0.1...</td>\n",
       "      <td>[325, 247, 60, 46, 2, 224, 321, 217, 114, 315]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4889960362541056</td>\n",
       "      <td>[0.9423247575759888, 0.05588565394282341, 0.00...</td>\n",
       "      <td>[112, 49, 310, 163, 167, 260, 215, 147, 32, 159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4622917889425408</td>\n",
       "      <td>[0.8748500347137451, 0.06827808171510696, 0.04...</td>\n",
       "      <td>[324, 329, 87, 59, 20, 86, 6, 271, 35, 326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5701122884894720</td>\n",
       "      <td>[0.9852563738822937, 0.014268704690039158, 0.0...</td>\n",
       "      <td>[194, 38, 148, 167, 70, 229, 125, 227, 259, 282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4963332144496640</td>\n",
       "      <td>[0.7232864499092102, 0.04579315334558487, 0.02...</td>\n",
       "      <td>[188, 246, 151, 310, 161, 167, 326, 257, 116, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5061933910720512  [0.34392818808555603, 0.29753392934799194, 0.1...   \n",
       "1  4889960362541056  [0.9423247575759888, 0.05588565394282341, 0.00...   \n",
       "2  4622917889425408  [0.8748500347137451, 0.06827808171510696, 0.04...   \n",
       "3  5701122884894720  [0.9852563738822937, 0.014268704690039158, 0.0...   \n",
       "4  4963332144496640  [0.7232864499092102, 0.04579315334558487, 0.02...   \n",
       "\n",
       "                                       class_id_elmo  \n",
       "0     [325, 247, 60, 46, 2, 224, 321, 217, 114, 315]  \n",
       "1   [112, 49, 310, 163, 167, 260, 215, 147, 32, 159]  \n",
       "2        [324, 329, 87, 59, 20, 86, 6, 271, 35, 326]  \n",
       "3   [194, 38, 148, 167, 70, 229, 125, 227, 259, 282]  \n",
       "4  [188, 246, 151, 310, 161, 167, 326, 257, 116, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elmo = pd.read_csv('../validation_elmo.csv', header=None, names=column_names_elmo)\n",
    "df_elmo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_alvin = '../submission/valid-null.prob.uint8.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399660"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_linc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5054234925989888</td>\n",
       "      <td>[0.9982976317405701, 0.00025638070655986667, 0...</td>\n",
       "      <td>[0, 217, 308, 30, 81, 165, 58, 85, 38, 206]</td>\n",
       "      <td>[1.0, 3.544855381454326e-11, 2.811725505202922...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 171, 70, 74, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5754535014301696</td>\n",
       "      <td>[0.9981287121772766, 0.0008819419308565557, 0....</td>\n",
       "      <td>[0, 306, 44, 190, 286, 297, 319, 244, 330, 165]</td>\n",
       "      <td>[1.0, 2.777928109765071e-08, 1.150913586656088...</td>\n",
       "      <td>[0, 165, 306, 226, 264, 190, 74, 171, 240, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6010760482258944</td>\n",
       "      <td>[0.6661585569381714, 0.2732973098754883, 0.014...</td>\n",
       "      <td>[270, 225, 58, 74, 337, 0, 81, 55, 254, 319]</td>\n",
       "      <td>[0.9997758269309998, 0.00015856364916544408, 3...</td>\n",
       "      <td>[0, 306, 225, 319, 337, 166, 171, 59, 282, 264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6677025135788032</td>\n",
       "      <td>[0.3110988140106201, 0.24152500927448273, 0.19...</td>\n",
       "      <td>[243, 226, 0, 1, 130, 251, 161, 279, 131, 114]</td>\n",
       "      <td>[0.9987855553627014, 0.0010346819180995226, 6....</td>\n",
       "      <td>[0, 240, 264, 226, 126, 114, 46, 131, 116, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5017604076863488</td>\n",
       "      <td>[0.9166284799575806, 0.027700455859303474, 0.0...</td>\n",
       "      <td>[0, 30, 145, 124, 319, 17, 70, 206, 71, 219]</td>\n",
       "      <td>[1.0, 1.7897846538161843e-09, 1.20063547992543...</td>\n",
       "      <td>[0, 306, 44, 70, 165, 171, 72, 264, 226, 240]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  probabilities_aye  \\\n",
       "0  5054234925989888  [0.9982976317405701, 0.00025638070655986667, 0...   \n",
       "1  5754535014301696  [0.9981287121772766, 0.0008819419308565557, 0....   \n",
       "2  6010760482258944  [0.6661585569381714, 0.2732973098754883, 0.014...   \n",
       "3  6677025135788032  [0.3110988140106201, 0.24152500927448273, 0.19...   \n",
       "4  5017604076863488  [0.9166284799575806, 0.027700455859303474, 0.0...   \n",
       "\n",
       "                                      class_id_aye  \\\n",
       "0      [0, 217, 308, 30, 81, 165, 58, 85, 38, 206]   \n",
       "1  [0, 306, 44, 190, 286, 297, 319, 244, 330, 165]   \n",
       "2     [270, 225, 58, 74, 337, 0, 81, 55, 254, 319]   \n",
       "3   [243, 226, 0, 1, 130, 251, 161, 279, 131, 114]   \n",
       "4     [0, 30, 145, 124, 319, 17, 70, 206, 71, 219]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [1.0, 3.544855381454326e-11, 2.811725505202922...   \n",
       "1  [1.0, 2.777928109765071e-08, 1.150913586656088...   \n",
       "2  [0.9997758269309998, 0.00015856364916544408, 3...   \n",
       "3  [0.9987855553627014, 0.0010346819180995226, 6....   \n",
       "4  [1.0, 1.7897846538161843e-09, 1.20063547992543...   \n",
       "\n",
       "                                     class_id_linc  \n",
       "0    [0, 165, 306, 226, 264, 171, 70, 74, 240, 46]  \n",
       "1   [0, 165, 306, 226, 264, 190, 74, 171, 240, 46]  \n",
       "2  [0, 306, 225, 319, 337, 166, 171, 59, 282, 264]  \n",
       "3   [0, 240, 264, 226, 126, 114, 46, 131, 116, 72]  \n",
       "4    [0, 306, 44, 70, 165, 171, 72, 264, 226, 240]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aye_linc = pd.merge(df_aye, df_linc, on='key_id')\n",
    "df_aye_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399660\n"
     ]
    }
   ],
   "source": [
    "print(len(df_aye_linc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5061933910720512</td>\n",
       "      <td>[0.34392818808555603, 0.29753392934799194, 0.1...</td>\n",
       "      <td>[325, 247, 60, 46, 2, 224, 321, 217, 114, 315]</td>\n",
       "      <td>[0.4996110796928406, 0.25497156381607056, 0.14...</td>\n",
       "      <td>[250, 325, 49, 321, 63, 5, 315, 117, 227, 220]</td>\n",
       "      <td>[0.6040798425674438, 0.2438904494047165, 0.131...</td>\n",
       "      <td>[250, 49, 325, 63, 117, 321, 5, 227, 220, 317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4889960362541056</td>\n",
       "      <td>[0.9423247575759888, 0.05588565394282341, 0.00...</td>\n",
       "      <td>[112, 49, 310, 163, 167, 260, 215, 147, 32, 159]</td>\n",
       "      <td>[0.7215479016304016, 0.23035041987895966, 0.00...</td>\n",
       "      <td>[115, 263, 310, 166, 150, 63, 52, 162, 155, 25]</td>\n",
       "      <td>[0.9994038343429565, 0.00034258264349773526, 8...</td>\n",
       "      <td>[115, 166, 52, 310, 72, 14, 150, 159, 142, 263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4622917889425408</td>\n",
       "      <td>[0.8748500347137451, 0.06827808171510696, 0.04...</td>\n",
       "      <td>[324, 329, 87, 59, 20, 86, 6, 271, 35, 326]</td>\n",
       "      <td>[0.8504902124404907, 0.09970162808895111, 0.04...</td>\n",
       "      <td>[324, 90, 311, 89, 313, 326, 196, 329, 47, 289]</td>\n",
       "      <td>[0.9751306176185608, 0.01563180983066559, 0.00...</td>\n",
       "      <td>[324, 90, 329, 197, 62, 311, 193, 23, 26, 223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5701122884894720</td>\n",
       "      <td>[0.9852563738822937, 0.014268704690039158, 0.0...</td>\n",
       "      <td>[194, 38, 148, 167, 70, 229, 125, 227, 259, 282]</td>\n",
       "      <td>[0.7247165441513062, 0.26686957478523254, 0.00...</td>\n",
       "      <td>[41, 197, 36, 232, 283, 29, 73, 262, 128, 132]</td>\n",
       "      <td>[0.9520771503448486, 0.04581376910209656, 0.00...</td>\n",
       "      <td>[197, 41, 170, 151, 73, 232, 285, 36, 191, 262]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4963332144496640</td>\n",
       "      <td>[0.7232864499092102, 0.04579315334558487, 0.02...</td>\n",
       "      <td>[188, 246, 151, 310, 161, 167, 326, 257, 116, ...</td>\n",
       "      <td>[0.6322354674339294, 0.10927347093820572, 0.08...</td>\n",
       "      <td>[166, 154, 249, 233, 260, 310, 136, 191, 69, 170]</td>\n",
       "      <td>[0.9996448755264282, 0.00011929067113669589, 2...</td>\n",
       "      <td>[191, 36, 78, 93, 285, 309, 301, 178, 234, 289]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5061933910720512  [0.34392818808555603, 0.29753392934799194, 0.1...   \n",
       "1  4889960362541056  [0.9423247575759888, 0.05588565394282341, 0.00...   \n",
       "2  4622917889425408  [0.8748500347137451, 0.06827808171510696, 0.04...   \n",
       "3  5701122884894720  [0.9852563738822937, 0.014268704690039158, 0.0...   \n",
       "4  4963332144496640  [0.7232864499092102, 0.04579315334558487, 0.02...   \n",
       "\n",
       "                                       class_id_elmo  \\\n",
       "0     [325, 247, 60, 46, 2, 224, 321, 217, 114, 315]   \n",
       "1   [112, 49, 310, 163, 167, 260, 215, 147, 32, 159]   \n",
       "2        [324, 329, 87, 59, 20, 86, 6, 271, 35, 326]   \n",
       "3   [194, 38, 148, 167, 70, 229, 125, 227, 259, 282]   \n",
       "4  [188, 246, 151, 310, 161, 167, 326, 257, 116, ...   \n",
       "\n",
       "                                   probabilities_aye  \\\n",
       "0  [0.4996110796928406, 0.25497156381607056, 0.14...   \n",
       "1  [0.7215479016304016, 0.23035041987895966, 0.00...   \n",
       "2  [0.8504902124404907, 0.09970162808895111, 0.04...   \n",
       "3  [0.7247165441513062, 0.26686957478523254, 0.00...   \n",
       "4  [0.6322354674339294, 0.10927347093820572, 0.08...   \n",
       "\n",
       "                                        class_id_aye  \\\n",
       "0     [250, 325, 49, 321, 63, 5, 315, 117, 227, 220]   \n",
       "1    [115, 263, 310, 166, 150, 63, 52, 162, 155, 25]   \n",
       "2    [324, 90, 311, 89, 313, 326, 196, 329, 47, 289]   \n",
       "3     [41, 197, 36, 232, 283, 29, 73, 262, 128, 132]   \n",
       "4  [166, 154, 249, 233, 260, 310, 136, 191, 69, 170]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [0.6040798425674438, 0.2438904494047165, 0.131...   \n",
       "1  [0.9994038343429565, 0.00034258264349773526, 8...   \n",
       "2  [0.9751306176185608, 0.01563180983066559, 0.00...   \n",
       "3  [0.9520771503448486, 0.04581376910209656, 0.00...   \n",
       "4  [0.9996448755264282, 0.00011929067113669589, 2...   \n",
       "\n",
       "                                     class_id_linc  \n",
       "0   [250, 49, 325, 63, 117, 321, 5, 227, 220, 317]  \n",
       "1  [115, 166, 52, 310, 72, 14, 150, 159, 142, 263]  \n",
       "2   [324, 90, 329, 197, 62, 311, 193, 23, 26, 223]  \n",
       "3  [197, 41, 170, 151, 73, 232, 285, 36, 191, 262]  \n",
       "4  [191, 36, 78, 93, 285, 309, 301, 178, 234, 289]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aye_linc_elmo = pd.merge(df_elmo, df_aye_linc, on='key_id')\n",
    "df_aye_linc_elmo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399660\n"
     ]
    }
   ],
   "source": [
    "print(len(df_aye_linc_elmo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_aye_linc\n",
    "del df_aye\n",
    "del df_linc\n",
    "del df_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>label</th>\n",
       "      <th>npy_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5054234925989888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5754535014301696</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6010760482258944</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6677025135788032</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5017604076863488</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id  label  npy_index\n",
       "0  5054234925989888      0          0\n",
       "1  5754535014301696      0          1\n",
       "2  6010760482258944      0          2\n",
       "3  6677025135788032      0          3\n",
       "4  5017604076863488      0          4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv('../input/valid_simplified.csv', usecols=['key_id', 'word'])\n",
    "df_labels['label'] = df_labels['word'].apply(lambda x: CLASS_NAME.index(x.replace(' ', '_')))\n",
    "df_labels['npy_index'] = df_labels.index\n",
    "df_labels = df_labels.drop(columns=['word'])\n",
    "df_labels.head()\n",
    "# df_labels_new = df_labels.set_index('key_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "      <th>label</th>\n",
       "      <th>npy_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5061933910720512</td>\n",
       "      <td>[0.34392818808555603, 0.29753392934799194, 0.1...</td>\n",
       "      <td>[325, 247, 60, 46, 2, 224, 321, 217, 114, 315]</td>\n",
       "      <td>[0.4996110796928406, 0.25497156381607056, 0.14...</td>\n",
       "      <td>[250, 325, 49, 321, 63, 5, 315, 117, 227, 220]</td>\n",
       "      <td>[0.6040798425674438, 0.2438904494047165, 0.131...</td>\n",
       "      <td>[250, 49, 325, 63, 117, 321, 5, 227, 220, 317]</td>\n",
       "      <td>250</td>\n",
       "      <td>2503955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4889960362541056</td>\n",
       "      <td>[0.9423247575759888, 0.05588565394282341, 0.00...</td>\n",
       "      <td>[112, 49, 310, 163, 167, 260, 215, 147, 32, 159]</td>\n",
       "      <td>[0.7215479016304016, 0.23035041987895966, 0.00...</td>\n",
       "      <td>[115, 263, 310, 166, 150, 63, 52, 162, 155, 25]</td>\n",
       "      <td>[0.9994038343429565, 0.00034258264349773526, 8...</td>\n",
       "      <td>[115, 166, 52, 310, 72, 14, 150, 159, 142, 263]</td>\n",
       "      <td>115</td>\n",
       "      <td>1158283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4622917889425408</td>\n",
       "      <td>[0.8748500347137451, 0.06827808171510696, 0.04...</td>\n",
       "      <td>[324, 329, 87, 59, 20, 86, 6, 271, 35, 326]</td>\n",
       "      <td>[0.8504902124404907, 0.09970162808895111, 0.04...</td>\n",
       "      <td>[324, 90, 311, 89, 313, 326, 196, 329, 47, 289]</td>\n",
       "      <td>[0.9751306176185608, 0.01563180983066559, 0.00...</td>\n",
       "      <td>[324, 90, 329, 197, 62, 311, 193, 23, 26, 223]</td>\n",
       "      <td>324</td>\n",
       "      <td>3249871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5701122884894720</td>\n",
       "      <td>[0.9852563738822937, 0.014268704690039158, 0.0...</td>\n",
       "      <td>[194, 38, 148, 167, 70, 229, 125, 227, 259, 282]</td>\n",
       "      <td>[0.7247165441513062, 0.26686957478523254, 0.00...</td>\n",
       "      <td>[41, 197, 36, 232, 283, 29, 73, 262, 128, 132]</td>\n",
       "      <td>[0.9520771503448486, 0.04581376910209656, 0.00...</td>\n",
       "      <td>[197, 41, 170, 151, 73, 232, 285, 36, 191, 262]</td>\n",
       "      <td>197</td>\n",
       "      <td>1973134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4963332144496640</td>\n",
       "      <td>[0.7232864499092102, 0.04579315334558487, 0.02...</td>\n",
       "      <td>[188, 246, 151, 310, 161, 167, 326, 257, 116, ...</td>\n",
       "      <td>[0.6322354674339294, 0.10927347093820572, 0.08...</td>\n",
       "      <td>[166, 154, 249, 233, 260, 310, 136, 191, 69, 170]</td>\n",
       "      <td>[0.9996448755264282, 0.00011929067113669589, 2...</td>\n",
       "      <td>[191, 36, 78, 93, 285, 309, 301, 178, 234, 289]</td>\n",
       "      <td>191</td>\n",
       "      <td>1917524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5061933910720512  [0.34392818808555603, 0.29753392934799194, 0.1...   \n",
       "1  4889960362541056  [0.9423247575759888, 0.05588565394282341, 0.00...   \n",
       "2  4622917889425408  [0.8748500347137451, 0.06827808171510696, 0.04...   \n",
       "3  5701122884894720  [0.9852563738822937, 0.014268704690039158, 0.0...   \n",
       "4  4963332144496640  [0.7232864499092102, 0.04579315334558487, 0.02...   \n",
       "\n",
       "                                       class_id_elmo  \\\n",
       "0     [325, 247, 60, 46, 2, 224, 321, 217, 114, 315]   \n",
       "1   [112, 49, 310, 163, 167, 260, 215, 147, 32, 159]   \n",
       "2        [324, 329, 87, 59, 20, 86, 6, 271, 35, 326]   \n",
       "3   [194, 38, 148, 167, 70, 229, 125, 227, 259, 282]   \n",
       "4  [188, 246, 151, 310, 161, 167, 326, 257, 116, ...   \n",
       "\n",
       "                                   probabilities_aye  \\\n",
       "0  [0.4996110796928406, 0.25497156381607056, 0.14...   \n",
       "1  [0.7215479016304016, 0.23035041987895966, 0.00...   \n",
       "2  [0.8504902124404907, 0.09970162808895111, 0.04...   \n",
       "3  [0.7247165441513062, 0.26686957478523254, 0.00...   \n",
       "4  [0.6322354674339294, 0.10927347093820572, 0.08...   \n",
       "\n",
       "                                        class_id_aye  \\\n",
       "0     [250, 325, 49, 321, 63, 5, 315, 117, 227, 220]   \n",
       "1    [115, 263, 310, 166, 150, 63, 52, 162, 155, 25]   \n",
       "2    [324, 90, 311, 89, 313, 326, 196, 329, 47, 289]   \n",
       "3     [41, 197, 36, 232, 283, 29, 73, 262, 128, 132]   \n",
       "4  [166, 154, 249, 233, 260, 310, 136, 191, 69, 170]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [0.6040798425674438, 0.2438904494047165, 0.131...   \n",
       "1  [0.9994038343429565, 0.00034258264349773526, 8...   \n",
       "2  [0.9751306176185608, 0.01563180983066559, 0.00...   \n",
       "3  [0.9520771503448486, 0.04581376910209656, 0.00...   \n",
       "4  [0.9996448755264282, 0.00011929067113669589, 2...   \n",
       "\n",
       "                                     class_id_linc  label  npy_index  \n",
       "0   [250, 49, 325, 63, 117, 321, 5, 227, 220, 317]    250    2503955  \n",
       "1  [115, 166, 52, 310, 72, 14, 150, 159, 142, 263]    115    1158283  \n",
       "2   [324, 90, 329, 197, 62, 311, 193, 23, 26, 223]    324    3249871  \n",
       "3  [197, 41, 170, 151, 73, 232, 285, 36, 191, 262]    197    1973134  \n",
       "4  [191, 36, 78, 93, 285, 309, 301, 178, 234, 289]    191    1917524  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aye_linc_elmo_label = pd.merge(df_aye_linc_elmo, df_labels, on='key_id')\n",
    "df_aye_linc_elmo_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399660"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aye_linc_elmo_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_aye_linc_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_uint8_to_float32(x, scale=255):\n",
    "    return (x/scale).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, prediction_df, npy_file, mode='train'):\n",
    "        super(PredictionDataset, self).__init__()\n",
    "\n",
    "        self.mode       = mode\n",
    "        self.df     = prediction_df\n",
    "        self.npy_pred_int = np.load(npy_file)\n",
    "        \n",
    "        lista = [i for i in range(304,307)]\n",
    "        listb = [i for i in range(0,304)]\n",
    "        listc = [i for i in range(307,340)]\n",
    "        self.corrected_ind = lista + listb + listc\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         construct prediction tensor from dataframe\n",
    "        row = self.df.iloc[index]\n",
    "        prob1 = ast.literal_eval(row['probabilities_aye'])\n",
    "        prob2 = ast.literal_eval(row['probabilities_linc'])\n",
    "        prob3 = ast.literal_eval(row['probabilities_elmo'])\n",
    "#         prob4 = ast.literal_eval(row['probabilities_alvin'])\n",
    "        \n",
    "        classes1 = ast.literal_eval(row['class_id_aye'])\n",
    "        classes2 = ast.literal_eval(row['class_id_linc'])\n",
    "        classes3 = ast.literal_eval(row['class_id_elmo'])\n",
    "#         classes4 = ast.literal_eval(row['class_id_alvin'])\n",
    "        \n",
    "        pred1 = np.zeros([340])\n",
    "        pred2 = np.zeros([340])\n",
    "        pred3 = np.zeros([340])\n",
    "#         pred4 = np.zeros([340])\n",
    "        \n",
    "        pred1[classes1] = prob1\n",
    "        pred2[classes2] = prob2\n",
    "        pred3[classes3] = prob3\n",
    "        pred3[self.corrected_ind] = pred3\n",
    "#         pred4[classes4] = prob4\n",
    "        npy_index = row['npy_index']\n",
    "        pred4 = self.npy_pred_int[npy_index]\n",
    "        pred4 = np_uint8_to_float32(pred4)\n",
    "\n",
    "        label = row['label']\n",
    "#         print('pred1: ', pred1)\n",
    "#         print('pred2: ', pred2)\n",
    "        # combined_pred = np.concatenate([pred1, pred2])\n",
    "#         combined_pred = np.concatenate([pred1, pred2, pred3, pred4])\n",
    "        \n",
    "        combined_pred = np.stack([pred1, pred2, pred3, pred4], axis=1)\n",
    "\n",
    "        if self.mode=='train':\n",
    "            return combined_pred, label\n",
    "        elif self.mode=='test':\n",
    "            return combined_pred, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.zeros([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred = np.stack([p1, p1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = PredictionDataset(df_aye_linc_elmo_label, npy_alvin, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:  (array([[0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.00784314],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), 250)\n",
      "sample:  (array([[0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.00392157],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , 0.00392157],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), 115)\n",
      "sample:  (array([[0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , 0.00784314],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), 324)\n",
      "sample:  (array([[0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , 0.00392157],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]]), 197)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_dataset)):\n",
    "    sample = pred_dataset[i]\n",
    "\n",
    "    print(\"sample: \", sample)\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000, 0.0039],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stensor = torch.tensor(sample[0])\n",
    "stensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0314],\n",
       "        [-1.2882],\n",
       "        [ 0.4238],\n",
       "        [ 1.6843]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.randn([4, 1], requires_grad=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0330],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0004],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0060],\n",
       "        [ 0.0113],\n",
       "        [ 0.0000],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.6951],\n",
       "        [ 0.0000],\n",
       "        [ 0.0198],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0198],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0134],\n",
       "        [ 0.0000],\n",
       "        [ 0.0330],\n",
       "        [ 0.0000],\n",
       "        [ 0.0001],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0067],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [-0.0004],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0060],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0264],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.4374],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0066],\n",
       "        [-0.9314],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0132],\n",
       "        [ 0.0132],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0143],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0132],\n",
       "        [ 0.0000],\n",
       "        [ 0.0001],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0528],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0073],\n",
       "        [ 0.0000],\n",
       "        [ 0.0064],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.1321],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0132],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0066],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = stensor.float().mm(weights)\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([340, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([340, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3125, -0.1045,  1.0468,  0.9481],\n",
       "        [ 0.1141,  0.4884,  0.0434,  1.1812],\n",
       "        [ 0.3076,  0.8826, -0.2219,  0.6923],\n",
       "        [-1.4780,  0.1656,  0.2772, -0.0851],\n",
       "        [ 1.2100,  1.3371, -1.3723, -1.1956],\n",
       "        [-0.7738, -0.6538,  0.2228,  1.5589],\n",
       "        [-0.0960, -0.3591,  1.0863,  0.7233]], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.randn([7, 4], requires_grad=True)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3125,  0.1141,  0.3076, -1.4780,  1.2100, -0.7738, -0.0960],\n",
       "        [-0.1045,  0.4884,  0.8826,  0.1656,  1.3371, -0.6538, -0.3591],\n",
       "        [ 1.0468,  0.0434, -0.2219,  0.2772, -1.3723,  0.2228,  1.0863],\n",
       "        [ 0.9481,  1.1812,  0.6923, -0.0851, -1.1956,  1.5589,  0.7233]],\n",
       "       grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([i for i in range(340)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = DataLoader(\n",
    "                    pred_dataset,\n",
    "                    #sampler     = FixLengthRandomSamplerWithProbability(train_dataset, probability),\n",
    "                    #sampler     = FixLengthRandomSampler(train_dataset),\n",
    "                    #sampler     = ConstantSampler(train_dataset,[31]*batch_size*100),\n",
    "                    sampler     = RandomSampler(pred_dataset),\n",
    "                    batch_size  = batch_size,\n",
    "                    drop_last   = True,\n",
    "                    num_workers = 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  tensor([202, 135, 109,  69,  10,  27, 327, 213, 164, 257, 189, 227, 139, 284,\n",
      "        178, 113,  31,  56, 187, 242,  36, 196, 108, 185, 118, 112, 116, 317,\n",
      "         86, 205, 252, 107,  80,  51, 118, 269,  57, 111, 232, 107,   3,   9,\n",
      "         41, 195,  17, 286, 284, 254, 166,  53,  67, 130, 237,  35,  22, 108,\n",
      "         76, 109,  91,  84,  78, 125, 287, 337, 175, 222,  39,  52,   2, 135,\n",
      "         67, 258, 223,   7,  43,   2, 122, 123,  31, 334,  31,  27,  65, 164,\n",
      "        193, 194,  68, 265,  64, 291, 220, 254,  57,  24, 172,  89,  92, 290,\n",
      "        130, 337, 250, 121, 207, 314, 260, 184, 198, 171, 284, 261, 146,   3,\n",
      "         65, 334, 256, 212,  93, 166, 189, 262,  42,  74, 226,  76, 307,  44,\n",
      "        164, 303])\n",
      "input:  tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2414, 0.0350, 0.0066, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0001, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0001, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], dtype=torch.float64)\n",
      "input.shape:  torch.Size([128, 340, 4])\n",
      "label:  tensor([187, 318,  46, 145, 145, 177,   2, 109,  82, 186, 242, 249, 201, 256,\n",
      "        168, 108,  29, 103, 328, 205, 149,  20, 101, 169, 151, 165,  10,  15,\n",
      "        258,  46, 246, 335,  45, 262, 324, 273, 129, 320, 127, 152,   8, 101,\n",
      "        289, 231, 333, 128,  51, 230, 302, 308,  12,  40, 119,  11, 145, 270,\n",
      "        194, 315, 217, 123,  88, 299, 315,  13, 326, 197,  52,  34, 269, 147,\n",
      "        119, 269,  93,  47, 244, 172,  56,  42, 299, 153, 210, 322,  92, 160,\n",
      "        166,  70, 285, 125, 119, 313, 139, 209,  53, 310, 184, 254, 163, 198,\n",
      "        273, 188,  81, 152, 263,  75, 161,  12, 304,   3, 147, 335, 328, 215,\n",
      "        316,  33, 209, 109, 206, 298, 117, 317, 298,  23,  50, 257, 291, 146,\n",
      "         80, 269])\n",
      "input:  tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0002, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], dtype=torch.float64)\n",
      "input.shape:  torch.Size([128, 340, 4])\n",
      "label:  tensor([307, 189, 227, 249, 308,  67, 173,  69, 269, 149, 320, 283, 268, 205,\n",
      "        283, 196, 257, 135, 132, 312, 220, 249,   7, 167,  63, 305, 191, 299,\n",
      "        282,  28, 132, 144, 241,  55,  68, 334, 272,   5, 209,  23, 300, 228,\n",
      "        121, 200, 251, 262, 141,  42, 130,  12, 160, 184, 322,  62, 326, 280,\n",
      "        323,  64, 323, 188, 200, 160, 164, 206, 114, 154,  53, 148, 229, 293,\n",
      "        105, 188, 330, 314, 244, 247, 223, 133, 179,  35,   2, 307, 170, 263,\n",
      "        154, 322, 121, 228, 277, 286,  74,  53,  19, 178, 222, 243, 198, 113,\n",
      "         14, 130, 279, 312,  44, 335, 127, 271, 259,  50, 129, 289, 139, 335,\n",
      "        111,  12,  42, 195,  37,  15, 130,  17, 260,  39, 256,  53,   9,  28,\n",
      "        168, 287])\n",
      "input:  tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0001, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0078],\n",
      "         [0.0101, 0.1060, 0.0229, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0118],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0118],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0002, 0.0000, 0.0006, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000, 0.0039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]], dtype=torch.float64)\n",
      "input.shape:  torch.Size([128, 340, 4])\n"
     ]
    }
   ],
   "source": [
    "debug_iter = 0\n",
    "for input, label in train_loader:\n",
    "    print(\"label: \", label)\n",
    "    print(\"input: \", input)\n",
    "    print(\"input.shape: \", input.shape)\n",
    "    debug_iter += 1\n",
    "    if debug_iter ==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6341030599196672</td>\n",
       "      <td>[0.875200092792511, 0.0850764587521553, 0.0067...</td>\n",
       "      <td>[330, 0, 306, 226, 196, 38, 243, 258, 104, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752894672764928</td>\n",
       "      <td>[0.7669468522071838, 0.2051558941602707, 0.013...</td>\n",
       "      <td>[306, 0, 190, 337, 319, 297, 38, 17, 282, 44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6340305538252800</td>\n",
       "      <td>[0.9722824692726135, 0.008625700138509274, 0.0...</td>\n",
       "      <td>[0, 297, 71, 306, 246, 72, 70, 240, 260, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5375560035336192</td>\n",
       "      <td>[0.3941877484321594, 0.13361148536205292, 0.08...</td>\n",
       "      <td>[190, 319, 306, 13, 226, 182, 337, 92, 118, 38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5131120968466432</td>\n",
       "      <td>[0.7326681017875671, 0.18073998391628265, 0.08...</td>\n",
       "      <td>[0, 306, 190, 44, 244, 38, 337, 319, 17, 256]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  probabilities_aye  \\\n",
       "0  6341030599196672  [0.875200092792511, 0.0850764587521553, 0.0067...   \n",
       "1  4752894672764928  [0.7669468522071838, 0.2051558941602707, 0.013...   \n",
       "2  6340305538252800  [0.9722824692726135, 0.008625700138509274, 0.0...   \n",
       "3  5375560035336192  [0.3941877484321594, 0.13361148536205292, 0.08...   \n",
       "4  5131120968466432  [0.7326681017875671, 0.18073998391628265, 0.08...   \n",
       "\n",
       "                                      class_id_aye  \n",
       "0   [330, 0, 306, 226, 196, 38, 243, 258, 104, 92]  \n",
       "1    [306, 0, 190, 337, 319, 297, 38, 17, 282, 44]  \n",
       "2     [0, 297, 71, 306, 246, 72, 70, 240, 260, 46]  \n",
       "3  [190, 319, 306, 13, 226, 182, 337, 92, 118, 38]  \n",
       "4    [0, 306, 190, 44, 244, 38, 337, 319, 17, 256]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_aye = pd.read_csv('../test_aye.csv', header=None, names=column_names_aye)\n",
    "df_test_aye.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399660"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_aye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6341030599196672]</td>\n",
       "      <td>[1.0, 2.1944435601994883e-08, 3.87791709854923...</td>\n",
       "      <td>[0, 306, 226, 165, 44, 74, 171, 38, 264, 337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4752894672764928]</td>\n",
       "      <td>[0.9998251795768738, 0.00010532637679716572, 5...</td>\n",
       "      <td>[0, 306, 226, 38, 319, 190, 13, 209, 282, 198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6340305538252800]</td>\n",
       "      <td>[1.0, 2.8131068585679486e-09, 9.31472565746105...</td>\n",
       "      <td>[0, 226, 306, 46, 240, 264, 165, 70, 72, 74]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5375560035336192]</td>\n",
       "      <td>[0.9335849285125732, 0.028212666511535645, 0.0...</td>\n",
       "      <td>[0, 165, 297, 190, 85, 226, 264, 172, 306, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5131120968466432]</td>\n",
       "      <td>[0.9999998807907104, 9.554816671197841e-08, 9....</td>\n",
       "      <td>[0, 306, 226, 190, 72, 165, 171, 44, 319, 264]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               key_id                                 probabilities_linc  \\\n",
       "0  [6341030599196672]  [1.0, 2.1944435601994883e-08, 3.87791709854923...   \n",
       "1  [4752894672764928]  [0.9998251795768738, 0.00010532637679716572, 5...   \n",
       "2  [6340305538252800]  [1.0, 2.8131068585679486e-09, 9.31472565746105...   \n",
       "3  [5375560035336192]  [0.9335849285125732, 0.028212666511535645, 0.0...   \n",
       "4  [5131120968466432]  [0.9999998807907104, 9.554816671197841e-08, 9....   \n",
       "\n",
       "                                    class_id_linc  \n",
       "0   [0, 306, 226, 165, 44, 74, 171, 38, 264, 337]  \n",
       "1  [0, 306, 226, 38, 319, 190, 13, 209, 282, 198]  \n",
       "2    [0, 226, 306, 46, 240, 264, 165, 70, 72, 74]  \n",
       "3  [0, 165, 297, 190, 85, 226, 264, 172, 306, 13]  \n",
       "4  [0, 306, 226, 190, 72, 165, 171, 44, 319, 264]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_linc = pd.read_csv('../test_linc.csv', header=None, names=column_names_linc)\n",
    "df_test_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6341030599196672</td>\n",
       "      <td>[1.0, 2.1944435601994883e-08, 3.87791709854923...</td>\n",
       "      <td>[0, 306, 226, 165, 44, 74, 171, 38, 264, 337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752894672764928</td>\n",
       "      <td>[0.9998251795768738, 0.00010532637679716572, 5...</td>\n",
       "      <td>[0, 306, 226, 38, 319, 190, 13, 209, 282, 198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6340305538252800</td>\n",
       "      <td>[1.0, 2.8131068585679486e-09, 9.31472565746105...</td>\n",
       "      <td>[0, 226, 306, 46, 240, 264, 165, 70, 72, 74]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5375560035336192</td>\n",
       "      <td>[0.9335849285125732, 0.028212666511535645, 0.0...</td>\n",
       "      <td>[0, 165, 297, 190, 85, 226, 264, 172, 306, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5131120968466432</td>\n",
       "      <td>[0.9999998807907104, 9.554816671197841e-08, 9....</td>\n",
       "      <td>[0, 306, 226, 190, 72, 165, 171, 44, 319, 264]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_linc  \\\n",
       "0  6341030599196672  [1.0, 2.1944435601994883e-08, 3.87791709854923...   \n",
       "1  4752894672764928  [0.9998251795768738, 0.00010532637679716572, 5...   \n",
       "2  6340305538252800  [1.0, 2.8131068585679486e-09, 9.31472565746105...   \n",
       "3  5375560035336192  [0.9335849285125732, 0.028212666511535645, 0.0...   \n",
       "4  5131120968466432  [0.9999998807907104, 9.554816671197841e-08, 9....   \n",
       "\n",
       "                                    class_id_linc  \n",
       "0   [0, 306, 226, 165, 44, 74, 171, 38, 264, 337]  \n",
       "1  [0, 306, 226, 38, 319, 190, 13, 209, 282, 198]  \n",
       "2    [0, 226, 306, 46, 240, 264, 165, 70, 72, 74]  \n",
       "3  [0, 165, 297, 190, 85, 226, 264, 172, 306, 13]  \n",
       "4  [0, 306, 226, 190, 72, 165, 171, 44, 319, 264]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_linc['key_id'] = df_test_linc['key_id'].apply(lambda x: int(x[1:-1]))\n",
    "df_test_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_linc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5496308146110464</td>\n",
       "      <td>[0.9999761581420898, 2.042186497419607e-05, 1....</td>\n",
       "      <td>[310, 266, 127, 116, 320, 183, 20, 144, 185, 292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5329744327344128</td>\n",
       "      <td>[0.5435892939567566, 0.449998140335083, 0.0061...</td>\n",
       "      <td>[191, 86, 74, 202, 44, 78, 88, 40, 308, 298]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4711812702404608</td>\n",
       "      <td>[0.90434730052948, 0.08019158989191055, 0.0152...</td>\n",
       "      <td>[318, 42, 47, 171, 39, 126, 120, 102, 204, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5638393792823296</td>\n",
       "      <td>[0.7236577272415161, 0.25125938653945923, 0.01...</td>\n",
       "      <td>[80, 219, 90, 254, 22, 188, 63, 307, 5, 239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5863027096158208</td>\n",
       "      <td>[0.5292368531227112, 0.3533603250980377, 0.109...</td>\n",
       "      <td>[74, 191, 86, 298, 202, 11, 336, 144, 44, 138]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5496308146110464  [0.9999761581420898, 2.042186497419607e-05, 1....   \n",
       "1  5329744327344128  [0.5435892939567566, 0.449998140335083, 0.0061...   \n",
       "2  4711812702404608  [0.90434730052948, 0.08019158989191055, 0.0152...   \n",
       "3  5638393792823296  [0.7236577272415161, 0.25125938653945923, 0.01...   \n",
       "4  5863027096158208  [0.5292368531227112, 0.3533603250980377, 0.109...   \n",
       "\n",
       "                                       class_id_elmo  \n",
       "0  [310, 266, 127, 116, 320, 183, 20, 144, 185, 292]  \n",
       "1       [191, 86, 74, 202, 44, 78, 88, 40, 308, 298]  \n",
       "2     [318, 42, 47, 171, 39, 126, 120, 102, 204, 56]  \n",
       "3       [80, 219, 90, 254, 22, 188, 63, 307, 5, 239]  \n",
       "4     [74, 191, 86, 298, 202, 11, 336, 144, 44, 138]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_elmo = pd.read_csv('../test_elmo.csv', header=None, names=column_names_elmo)\n",
    "df_test_elmo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_test_alvin = '../submission/test-null.prob.uint8.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6341030599196672</td>\n",
       "      <td>[0.875200092792511, 0.0850764587521553, 0.0067...</td>\n",
       "      <td>[330, 0, 306, 226, 196, 38, 243, 258, 104, 92]</td>\n",
       "      <td>[1.0, 2.1944435601994883e-08, 3.87791709854923...</td>\n",
       "      <td>[0, 306, 226, 165, 44, 74, 171, 38, 264, 337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752894672764928</td>\n",
       "      <td>[0.7669468522071838, 0.2051558941602707, 0.013...</td>\n",
       "      <td>[306, 0, 190, 337, 319, 297, 38, 17, 282, 44]</td>\n",
       "      <td>[0.9998251795768738, 0.00010532637679716572, 5...</td>\n",
       "      <td>[0, 306, 226, 38, 319, 190, 13, 209, 282, 198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6340305538252800</td>\n",
       "      <td>[0.9722824692726135, 0.008625700138509274, 0.0...</td>\n",
       "      <td>[0, 297, 71, 306, 246, 72, 70, 240, 260, 46]</td>\n",
       "      <td>[1.0, 2.8131068585679486e-09, 9.31472565746105...</td>\n",
       "      <td>[0, 226, 306, 46, 240, 264, 165, 70, 72, 74]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5375560035336192</td>\n",
       "      <td>[0.3941877484321594, 0.13361148536205292, 0.08...</td>\n",
       "      <td>[190, 319, 306, 13, 226, 182, 337, 92, 118, 38]</td>\n",
       "      <td>[0.9335849285125732, 0.028212666511535645, 0.0...</td>\n",
       "      <td>[0, 165, 297, 190, 85, 226, 264, 172, 306, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5131120968466432</td>\n",
       "      <td>[0.7326681017875671, 0.18073998391628265, 0.08...</td>\n",
       "      <td>[0, 306, 190, 44, 244, 38, 337, 319, 17, 256]</td>\n",
       "      <td>[0.9999998807907104, 9.554816671197841e-08, 9....</td>\n",
       "      <td>[0, 306, 226, 190, 72, 165, 171, 44, 319, 264]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  probabilities_aye  \\\n",
       "0  6341030599196672  [0.875200092792511, 0.0850764587521553, 0.0067...   \n",
       "1  4752894672764928  [0.7669468522071838, 0.2051558941602707, 0.013...   \n",
       "2  6340305538252800  [0.9722824692726135, 0.008625700138509274, 0.0...   \n",
       "3  5375560035336192  [0.3941877484321594, 0.13361148536205292, 0.08...   \n",
       "4  5131120968466432  [0.7326681017875671, 0.18073998391628265, 0.08...   \n",
       "\n",
       "                                      class_id_aye  \\\n",
       "0   [330, 0, 306, 226, 196, 38, 243, 258, 104, 92]   \n",
       "1    [306, 0, 190, 337, 319, 297, 38, 17, 282, 44]   \n",
       "2     [0, 297, 71, 306, 246, 72, 70, 240, 260, 46]   \n",
       "3  [190, 319, 306, 13, 226, 182, 337, 92, 118, 38]   \n",
       "4    [0, 306, 190, 44, 244, 38, 337, 319, 17, 256]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [1.0, 2.1944435601994883e-08, 3.87791709854923...   \n",
       "1  [0.9998251795768738, 0.00010532637679716572, 5...   \n",
       "2  [1.0, 2.8131068585679486e-09, 9.31472565746105...   \n",
       "3  [0.9335849285125732, 0.028212666511535645, 0.0...   \n",
       "4  [0.9999998807907104, 9.554816671197841e-08, 9....   \n",
       "\n",
       "                                    class_id_linc  \n",
       "0   [0, 306, 226, 165, 44, 74, 171, 38, 264, 337]  \n",
       "1  [0, 306, 226, 38, 319, 190, 13, 209, 282, 198]  \n",
       "2    [0, 226, 306, 46, 240, 264, 165, 70, 72, 74]  \n",
       "3  [0, 165, 297, 190, 85, 226, 264, 172, 306, 13]  \n",
       "4  [0, 306, 226, 190, 72, 165, 171, 44, 319, 264]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_aye_linc = pd.merge(df_test_aye, df_test_linc, on='key_id')\n",
    "df_test_aye_linc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5496308146110464</td>\n",
       "      <td>[0.9999761581420898, 2.042186497419607e-05, 1....</td>\n",
       "      <td>[310, 266, 127, 116, 320, 183, 20, 144, 185, 292]</td>\n",
       "      <td>[0.9996577501296997, 0.00021973211551085114, 2...</td>\n",
       "      <td>[310, 70, 269, 100, 23, 336, 153, 147, 128, 309]</td>\n",
       "      <td>[0.9998773336410522, 9.525865607429296e-05, 3....</td>\n",
       "      <td>[310, 70, 269, 119, 81, 261, 328, 166, 23, 273]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5329744327344128</td>\n",
       "      <td>[0.5435892939567566, 0.449998140335083, 0.0061...</td>\n",
       "      <td>[191, 86, 74, 202, 44, 78, 88, 40, 308, 298]</td>\n",
       "      <td>[0.8065358400344849, 0.18072368204593658, 0.01...</td>\n",
       "      <td>[194, 89, 77, 205, 47, 301, 81, 43, 308, 221]</td>\n",
       "      <td>[0.681432843208313, 0.295911580324173, 0.01857...</td>\n",
       "      <td>[194, 89, 77, 205, 47, 14, 81, 326, 91, 43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4711812702404608</td>\n",
       "      <td>[0.90434730052948, 0.08019158989191055, 0.0152...</td>\n",
       "      <td>[318, 42, 47, 171, 39, 126, 120, 102, 204, 56]</td>\n",
       "      <td>[0.9290045499801636, 0.05997219681739807, 0.01...</td>\n",
       "      <td>[318, 45, 50, 129, 42, 257, 195, 172, 58, 287]</td>\n",
       "      <td>[0.7766790390014648, 0.2119411826133728, 0.003...</td>\n",
       "      <td>[318, 45, 50, 207, 129, 123, 195, 58, 42, 111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5638393792823296</td>\n",
       "      <td>[0.7236577272415161, 0.25125938653945923, 0.01...</td>\n",
       "      <td>[80, 219, 90, 254, 22, 188, 63, 307, 5, 239]</td>\n",
       "      <td>[0.5334019064903259, 0.21909023821353912, 0.15...</td>\n",
       "      <td>[66, 83, 93, 222, 191, 25, 307, 257, 149, 174]</td>\n",
       "      <td>[0.4962978661060333, 0.3247675597667694, 0.106...</td>\n",
       "      <td>[83, 222, 93, 66, 257, 25, 191, 242, 307, 236]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5863027096158208</td>\n",
       "      <td>[0.5292368531227112, 0.3533603250980377, 0.109...</td>\n",
       "      <td>[74, 191, 86, 298, 202, 11, 336, 144, 44, 138]</td>\n",
       "      <td>[0.7012451887130737, 0.16382674872875214, 0.13...</td>\n",
       "      <td>[77, 89, 194, 301, 47, 205, 20, 145, 39, 336]</td>\n",
       "      <td>[0.5619053244590759, 0.216669961810112, 0.1899...</td>\n",
       "      <td>[77, 194, 89, 301, 14, 47, 128, 81, 205, 20]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5496308146110464  [0.9999761581420898, 2.042186497419607e-05, 1....   \n",
       "1  5329744327344128  [0.5435892939567566, 0.449998140335083, 0.0061...   \n",
       "2  4711812702404608  [0.90434730052948, 0.08019158989191055, 0.0152...   \n",
       "3  5638393792823296  [0.7236577272415161, 0.25125938653945923, 0.01...   \n",
       "4  5863027096158208  [0.5292368531227112, 0.3533603250980377, 0.109...   \n",
       "\n",
       "                                       class_id_elmo  \\\n",
       "0  [310, 266, 127, 116, 320, 183, 20, 144, 185, 292]   \n",
       "1       [191, 86, 74, 202, 44, 78, 88, 40, 308, 298]   \n",
       "2     [318, 42, 47, 171, 39, 126, 120, 102, 204, 56]   \n",
       "3       [80, 219, 90, 254, 22, 188, 63, 307, 5, 239]   \n",
       "4     [74, 191, 86, 298, 202, 11, 336, 144, 44, 138]   \n",
       "\n",
       "                                   probabilities_aye  \\\n",
       "0  [0.9996577501296997, 0.00021973211551085114, 2...   \n",
       "1  [0.8065358400344849, 0.18072368204593658, 0.01...   \n",
       "2  [0.9290045499801636, 0.05997219681739807, 0.01...   \n",
       "3  [0.5334019064903259, 0.21909023821353912, 0.15...   \n",
       "4  [0.7012451887130737, 0.16382674872875214, 0.13...   \n",
       "\n",
       "                                       class_id_aye  \\\n",
       "0  [310, 70, 269, 100, 23, 336, 153, 147, 128, 309]   \n",
       "1     [194, 89, 77, 205, 47, 301, 81, 43, 308, 221]   \n",
       "2    [318, 45, 50, 129, 42, 257, 195, 172, 58, 287]   \n",
       "3    [66, 83, 93, 222, 191, 25, 307, 257, 149, 174]   \n",
       "4     [77, 89, 194, 301, 47, 205, 20, 145, 39, 336]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [0.9998773336410522, 9.525865607429296e-05, 3....   \n",
       "1  [0.681432843208313, 0.295911580324173, 0.01857...   \n",
       "2  [0.7766790390014648, 0.2119411826133728, 0.003...   \n",
       "3  [0.4962978661060333, 0.3247675597667694, 0.106...   \n",
       "4  [0.5619053244590759, 0.216669961810112, 0.1899...   \n",
       "\n",
       "                                     class_id_linc  \n",
       "0  [310, 70, 269, 119, 81, 261, 328, 166, 23, 273]  \n",
       "1      [194, 89, 77, 205, 47, 14, 81, 326, 91, 43]  \n",
       "2   [318, 45, 50, 207, 129, 123, 195, 58, 42, 111]  \n",
       "3   [83, 222, 93, 66, 257, 25, 191, 242, 307, 236]  \n",
       "4     [77, 194, 89, 301, 14, 47, 128, 81, 205, 20]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_aye_linc_elmo = pd.merge(df_test_elmo, df_test_aye_linc, on='key_id')\n",
    "df_test_aye_linc_elmo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3399660\n"
     ]
    }
   ],
   "source": [
    "print(len(df_test_aye_linc_elmo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test_aye_linc\n",
    "del df_test_aye\n",
    "del df_test_linc\n",
    "del df_test_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>label</th>\n",
       "      <th>npy_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6341030599196672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752894672764928</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6340305538252800</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5375560035336192</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5131120968466432</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id  label  npy_index\n",
       "0  6341030599196672      0          0\n",
       "1  4752894672764928      0          1\n",
       "2  6340305538252800      0          2\n",
       "3  5375560035336192      0          3\n",
       "4  5131120968466432      0          4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_labels = pd.read_csv('../input/test_simplified.csv', usecols=['key_id', 'word'])\n",
    "df_test_labels['label'] = df_test_labels['word'].apply(lambda x: CLASS_NAME.index(x.replace(' ', '_')))\n",
    "df_test_labels['npy_index'] = df_test_labels.index\n",
    "df_test_labels = df_test_labels.drop(columns=['word'])\n",
    "df_test_labels.head()\n",
    "# df_labels_new = df_labels.set_index('key_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>probabilities_elmo</th>\n",
       "      <th>class_id_elmo</th>\n",
       "      <th>probabilities_aye</th>\n",
       "      <th>class_id_aye</th>\n",
       "      <th>probabilities_linc</th>\n",
       "      <th>class_id_linc</th>\n",
       "      <th>label</th>\n",
       "      <th>npy_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5496308146110464</td>\n",
       "      <td>[0.9999761581420898, 2.042186497419607e-05, 1....</td>\n",
       "      <td>[310, 266, 127, 116, 320, 183, 20, 144, 185, 292]</td>\n",
       "      <td>[0.9996577501296997, 0.00021973211551085114, 2...</td>\n",
       "      <td>[310, 70, 269, 100, 23, 336, 153, 147, 128, 309]</td>\n",
       "      <td>[0.9998773336410522, 9.525865607429296e-05, 3....</td>\n",
       "      <td>[310, 70, 269, 119, 81, 261, 328, 166, 23, 273]</td>\n",
       "      <td>310</td>\n",
       "      <td>3104230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5329744327344128</td>\n",
       "      <td>[0.5435892939567566, 0.449998140335083, 0.0061...</td>\n",
       "      <td>[191, 86, 74, 202, 44, 78, 88, 40, 308, 298]</td>\n",
       "      <td>[0.8065358400344849, 0.18072368204593658, 0.01...</td>\n",
       "      <td>[194, 89, 77, 205, 47, 301, 81, 43, 308, 221]</td>\n",
       "      <td>[0.681432843208313, 0.295911580324173, 0.01857...</td>\n",
       "      <td>[194, 89, 77, 205, 47, 14, 81, 326, 91, 43]</td>\n",
       "      <td>89</td>\n",
       "      <td>898795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4711812702404608</td>\n",
       "      <td>[0.90434730052948, 0.08019158989191055, 0.0152...</td>\n",
       "      <td>[318, 42, 47, 171, 39, 126, 120, 102, 204, 56]</td>\n",
       "      <td>[0.9290045499801636, 0.05997219681739807, 0.01...</td>\n",
       "      <td>[318, 45, 50, 129, 42, 257, 195, 172, 58, 287]</td>\n",
       "      <td>[0.7766790390014648, 0.2119411826133728, 0.003...</td>\n",
       "      <td>[318, 45, 50, 207, 129, 123, 195, 58, 42, 111]</td>\n",
       "      <td>45</td>\n",
       "      <td>457225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5638393792823296</td>\n",
       "      <td>[0.7236577272415161, 0.25125938653945923, 0.01...</td>\n",
       "      <td>[80, 219, 90, 254, 22, 188, 63, 307, 5, 239]</td>\n",
       "      <td>[0.5334019064903259, 0.21909023821353912, 0.15...</td>\n",
       "      <td>[66, 83, 93, 222, 191, 25, 307, 257, 149, 174]</td>\n",
       "      <td>[0.4962978661060333, 0.3247675597667694, 0.106...</td>\n",
       "      <td>[83, 222, 93, 66, 257, 25, 191, 242, 307, 236]</td>\n",
       "      <td>222</td>\n",
       "      <td>2228132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5863027096158208</td>\n",
       "      <td>[0.5292368531227112, 0.3533603250980377, 0.109...</td>\n",
       "      <td>[74, 191, 86, 298, 202, 11, 336, 144, 44, 138]</td>\n",
       "      <td>[0.7012451887130737, 0.16382674872875214, 0.13...</td>\n",
       "      <td>[77, 89, 194, 301, 47, 205, 20, 145, 39, 336]</td>\n",
       "      <td>[0.5619053244590759, 0.216669961810112, 0.1899...</td>\n",
       "      <td>[77, 194, 89, 301, 14, 47, 128, 81, 205, 20]</td>\n",
       "      <td>77</td>\n",
       "      <td>773399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                 probabilities_elmo  \\\n",
       "0  5496308146110464  [0.9999761581420898, 2.042186497419607e-05, 1....   \n",
       "1  5329744327344128  [0.5435892939567566, 0.449998140335083, 0.0061...   \n",
       "2  4711812702404608  [0.90434730052948, 0.08019158989191055, 0.0152...   \n",
       "3  5638393792823296  [0.7236577272415161, 0.25125938653945923, 0.01...   \n",
       "4  5863027096158208  [0.5292368531227112, 0.3533603250980377, 0.109...   \n",
       "\n",
       "                                       class_id_elmo  \\\n",
       "0  [310, 266, 127, 116, 320, 183, 20, 144, 185, 292]   \n",
       "1       [191, 86, 74, 202, 44, 78, 88, 40, 308, 298]   \n",
       "2     [318, 42, 47, 171, 39, 126, 120, 102, 204, 56]   \n",
       "3       [80, 219, 90, 254, 22, 188, 63, 307, 5, 239]   \n",
       "4     [74, 191, 86, 298, 202, 11, 336, 144, 44, 138]   \n",
       "\n",
       "                                   probabilities_aye  \\\n",
       "0  [0.9996577501296997, 0.00021973211551085114, 2...   \n",
       "1  [0.8065358400344849, 0.18072368204593658, 0.01...   \n",
       "2  [0.9290045499801636, 0.05997219681739807, 0.01...   \n",
       "3  [0.5334019064903259, 0.21909023821353912, 0.15...   \n",
       "4  [0.7012451887130737, 0.16382674872875214, 0.13...   \n",
       "\n",
       "                                       class_id_aye  \\\n",
       "0  [310, 70, 269, 100, 23, 336, 153, 147, 128, 309]   \n",
       "1     [194, 89, 77, 205, 47, 301, 81, 43, 308, 221]   \n",
       "2    [318, 45, 50, 129, 42, 257, 195, 172, 58, 287]   \n",
       "3    [66, 83, 93, 222, 191, 25, 307, 257, 149, 174]   \n",
       "4     [77, 89, 194, 301, 47, 205, 20, 145, 39, 336]   \n",
       "\n",
       "                                  probabilities_linc  \\\n",
       "0  [0.9998773336410522, 9.525865607429296e-05, 3....   \n",
       "1  [0.681432843208313, 0.295911580324173, 0.01857...   \n",
       "2  [0.7766790390014648, 0.2119411826133728, 0.003...   \n",
       "3  [0.4962978661060333, 0.3247675597667694, 0.106...   \n",
       "4  [0.5619053244590759, 0.216669961810112, 0.1899...   \n",
       "\n",
       "                                     class_id_linc  label  npy_index  \n",
       "0  [310, 70, 269, 119, 81, 261, 328, 166, 23, 273]    310    3104230  \n",
       "1      [194, 89, 77, 205, 47, 14, 81, 326, 91, 43]     89     898795  \n",
       "2   [318, 45, 50, 207, 129, 123, 195, 58, 42, 111]     45     457225  \n",
       "3   [83, 222, 93, 66, 257, 25, 191, 242, 307, 236]    222    2228132  \n",
       "4     [77, 194, 89, 301, 14, 47, 128, 81, 205, 20]     77     773399  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_aye_linc_elmo_label = pd.merge(df_test_aye_linc_elmo, df_test_labels, on='key_id')\n",
    "df_test_aye_linc_elmo_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399660"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_aye_linc_elmo_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test_aye_linc_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "\n",
    "    def __init__(self, num_models=4, num_classes=340):\n",
    "        super(Ensemble, self).__init__()\n",
    "        \n",
    "        # self.linear1 = nn.Linear(in_features=num_classes*num_models, out_features=num_classes*2)\n",
    "        # self.linear2 = nn.Linear(in_features=num_classes*2, out_features=num_classes)\n",
    "        # self.relu  = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn([4, 1], requires_grad=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"x: \", x)\n",
    "#         print(\"self.weights: \", self.weights)\n",
    "#         weighted_sum_x = x.mm(self.weights)\n",
    "        weighted_sum_x = torch.matmul(x, self.weights)\n",
    "        \n",
    "        weighted_sum_x = torch.squeeze(weighted_sum_x, 2)\n",
    "        return weighted_sum_x\n",
    "    \n",
    "    def set_mode(self, mode, is_freeze_bn=False ):\n",
    "        self.mode = mode\n",
    "        if mode in ['eval', 'valid', 'test']:\n",
    "            self.eval()\n",
    "        elif mode in ['train']:\n",
    "            self.train()\n",
    "            if is_freeze_bn==True: ##freeze\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, BatchNorm2d):\n",
    "                        m.eval()\n",
    "                        m.weight.requires_grad = False\n",
    "                        m.bias.requires_grad   = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_ensemble():\n",
    "    out_dir = \\\n",
    "        '../output_ensemble'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    initial_checkpoint= None\n",
    "    \n",
    "    schduler  = NullScheduler(lr=0.01)\n",
    "    iter_save_interval = 2000\n",
    "    criterion          = softmax_cross_entropy_criterion\n",
    "\n",
    "\n",
    "    ## setup  -----------------------------------------------------------------------------\n",
    "    os.makedirs(out_dir +'/checkpoint', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/train', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/backup', exist_ok=True)\n",
    "    backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.train.txt',mode='a')\n",
    "    log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n",
    "    log.write('\\tSEED         = %u\\n' % SEED)\n",
    "    log.write('\\tPROJECT_PATH = %s\\n' % PROJECT_PATH)\n",
    "#     log.write('\\t__file__     = %s\\n' % __file__)\n",
    "    log.write('\\tout_dir      = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "    log.write('\\t<additional comments>\\n')\n",
    "    log.write('\\t  ... xxx baseline  ... \\n')\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    ## dataset ----------------------------------------\n",
    "    log.write('** dataset setting **\\n')\n",
    "    batch_size = 128  #16 #32\n",
    "\n",
    "#     train_dataset = DoodleDataset('train', 'train_0', train_augment)\n",
    "    train_dataset = PredictionDataset(df_aye_linc_elmo_label, npy_alvin, mode='train')\n",
    "    train_loader  = DataLoader(\n",
    "                        train_dataset,\n",
    "                        sampler     = RandomSampler(train_dataset),\n",
    "                        batch_size  = batch_size,\n",
    "                        drop_last   = True,\n",
    "                        num_workers = 2,)\n",
    "    \n",
    "#     debug\n",
    "    valid_dataset = PredictionDataset(df_test_aye_linc_elmo_label, npy_test_alvin, mode='train')\n",
    "    valid_loader  = DataLoader(\n",
    "                        valid_dataset,\n",
    "                        sampler     = RandomSampler(valid_dataset),\n",
    "                        batch_size  = batch_size,\n",
    "                        drop_last   = True,\n",
    "                        num_workers = 2,)\n",
    "    \n",
    "#     valid_dataset = PredictionDataset(df_aye_linc, mode='train')\n",
    "#     valid_loader  = DataLoader(\n",
    "#                         train_dataset,\n",
    "#                         sampler     = RandomSampler(valid_dataset),\n",
    "#                         batch_size  = batch_size,\n",
    "#                         drop_last   = True,\n",
    "#                         num_workers = 2,)\n",
    "\n",
    "\n",
    "    assert(len(train_dataset)>=batch_size)\n",
    "    log.write('batch_size = %d\\n'%(batch_size))\n",
    "    log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "    log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "    log.write('\\n')\n",
    "\n",
    "    ## net ----------------------------------------\n",
    "    log.write('** net setting **\\n')\n",
    "#     net = Net().cuda()\n",
    "    net = Ensemble(num_models=4, num_classes=340).cuda()\n",
    "\n",
    "    log.write('%s\\n'%(type(net)))\n",
    "    log.write('criterion=%s\\n'%criterion)\n",
    "    log.write('\\n')\n",
    "    \n",
    "#     print(\"net.parameters(): \", net.parameters())\n",
    "#     print(\"list(net.parameters()): \", list(net.parameters()))\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                          lr=schduler(0), momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "    num_iters   = 10000\n",
    "#     num_iters   = 1  *1000\n",
    "#     num_iters   = 300  *1000\n",
    "    iter_smooth = 20\n",
    "    iter_log    = 50\n",
    "#     iter_valid  = 100\n",
    "    iter_valid  = 1000\n",
    "    iter_save   = [0, num_iters-1]\\\n",
    "                   + list(range(0, num_iters, iter_save_interval))#1*1000\n",
    "\n",
    "    start_iter = 0\n",
    "    start_epoch= 0\n",
    "    rate       = 0\n",
    "    if initial_checkpoint is not None:\n",
    "        initial_optimizer = initial_checkpoint.replace('_model.pth','_optimizer.pth')\n",
    "        checkpoint  = torch.load(initial_optimizer)\n",
    "        start_iter  = checkpoint['iter' ]\n",
    "        start_epoch = checkpoint['epoch']\n",
    "\n",
    "        #rate = get_learning_rate(optimizer)  #load all except learning rate\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        #adjust_learning_rate(optimizer, rate)\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    log.write('schduler\\n  %s\\n'%(schduler))\n",
    "    log.write('\\n')\n",
    "\n",
    "    ## start training here! ##############################################\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('                    |------------ VALID -------------|-------- TRAIN/BATCH ----------|         \\n')\n",
    "    log.write('rate   iter  epoch  | loss   acc-1  acc-3   lb       | loss   acc-1  acc-3   lb      |  time   \\n')\n",
    "    log.write('----------------------------------------------------------------------------------------------------\\n')\n",
    "         \n",
    "\n",
    "    train_loss   = np.zeros(6,np.float32)\n",
    "    valid_loss   = np.zeros(6,np.float32)\n",
    "    batch_loss   = np.zeros(6,np.float32)\n",
    "    iter = 0\n",
    "    i    = 0\n",
    "    last_max_lb   = -1\n",
    "\n",
    "\n",
    "    start = timer()\n",
    "    while  iter<num_iters:\n",
    "        sum_train_loss = np.zeros(6,np.float32)\n",
    "        sum = 0\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for input, truth in train_loader:\n",
    "#         for input, truth, cache in train_loader:\n",
    "\n",
    "            len_train_dataset = len(train_dataset)\n",
    "#             batch_size = len(cache)\n",
    "            iter = i + start_iter\n",
    "            epoch = (iter-start_iter)*batch_size/len_train_dataset + start_epoch\n",
    "            num_samples = epoch*len_train_dataset\n",
    "\n",
    "\n",
    "            if (iter % iter_valid==0) and (iter!=0):\n",
    "                net.set_mode('valid')\n",
    "                valid_loss = do_valid(net, valid_loader, criterion, 500)\n",
    "                net.set_mode('train')\n",
    "\n",
    "                ##--------\n",
    "                # lb    = valid_loss[7]\n",
    "                # loss  = valid_loss[0] + valid_loss[4]\n",
    "                # last_max_lb = max(last_max_lb,lb)\n",
    "                # if last_max_lb-lb<0.005:\n",
    "                #     iter_save += [iter,]\n",
    "                # if loss-last_min_loss<0.005:\n",
    "                #     iter_save += [iter,]\n",
    "\n",
    "                asterisk = '*' if iter in iter_save else ' '\n",
    "                ##--------\n",
    "\n",
    "                print('\\r',end='',flush=True)\n",
    "                log.write('%0.4f %5.1f %6.1f | %0.3f  %0.3f  %0.3f  (%0.3f)%s  | %0.3f  %0.3f  %0.3f  (%0.3f)  | %s' % (\\\n",
    "                         rate, iter/1000, epoch,\n",
    "                         valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3],asterisk,\n",
    "                         train_loss[0], train_loss[1], train_loss[2], train_loss[3],\n",
    "                         time_to_str((timer() - start),'min'))\n",
    "                )\n",
    "                log.write('\\n')\n",
    "                time.sleep(0.01)\n",
    "\n",
    "            #if 0:\n",
    "            if iter in iter_save:\n",
    "                torch.save(net.state_dict(),out_dir +'/checkpoint/%08d_model.pth'%(iter))\n",
    "                torch.save({\n",
    "                    #'optimizer': optimizer.state_dict(),\n",
    "                    'iter'     : iter,\n",
    "                    'epoch'    : epoch,\n",
    "                }, out_dir +'/checkpoint/%08d_optimizer.pth'%(iter))\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # learning rate schduler -------------\n",
    "            lr = schduler(iter)\n",
    "            if lr<0 : break\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "            rate = get_learning_rate(optimizer)\n",
    "\n",
    "\n",
    "\n",
    "            # one iteration update  -------------\n",
    "            #net.set_mode('train',is_freeze_bn=True)\n",
    "            net.set_mode('train')\n",
    "            input = input.cuda().float()\n",
    "            truth = truth.cuda()\n",
    "\n",
    "            logit = data_parallel(net, input)\n",
    "#             print(\"logit.size(): \", logit.size())\n",
    "            loss  = criterion(logit, truth)\n",
    "            precision, top = metric(logit, truth)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #torch.nn.utils.clip_grad_norm(net.parameters(), 1)\n",
    "\n",
    "\n",
    "            # print statistics  ------------\n",
    "            batch_loss[:4] = np.array(( loss.item(), top[0].item(), top[2].item(), precision.item(),))\n",
    "            sum_train_loss += batch_loss\n",
    "            sum += 1\n",
    "            if iter%iter_smooth == 0:\n",
    "                train_loss = sum_train_loss/sum\n",
    "                sum_train_loss = np.zeros(6,np.float32)\n",
    "                sum = 0\n",
    "\n",
    "\n",
    "            print('\\r',end='',flush=True)\n",
    "            print('%0.4f %5.1f %6.1f | %0.3f  %0.3f  %0.3f  (%0.3f)%s  | %0.3f  %0.3f  %0.3f  (%0.3f)  | %s' % (\\\n",
    "                         rate, iter/1000, epoch,\n",
    "                         valid_loss[0], valid_loss[1], valid_loss[2], valid_loss[3],' ',\n",
    "                         batch_loss[0], batch_loss[1], batch_loss[2], batch_loss[3],\n",
    "                         time_to_str((timer() - start),'min'))\n",
    "            , end='',flush=True)\n",
    "            i=i+1\n",
    "\n",
    "\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    pass #-- end of all iterations --\n",
    "\n",
    "\n",
    "    if 1: #save last\n",
    "        torch.save(net.state_dict(),out_dir +'/checkpoint/%d_model.pth'%(i))\n",
    "        torch.save({\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'iter'     : i,\n",
    "            'epoch'    : epoch,\n",
    "        }, out_dir +'/checkpoint/%d_optimizer.pth'%(i))\n",
    "\n",
    "    log.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "896d44db6e26b05600e8ee53542387779b75fa5d"
   },
   "outputs": [],
   "source": [
    "# model32_resnet34.py\n",
    "\n",
    "def softmax_cross_entropy_criterion(logit, truth, is_average=True):\n",
    "#     print('logit: ', logit)\n",
    "#     print('truth', truth)\n",
    "#     print('logit.size(): ', logit.size())\n",
    "#     print('truth.size()', truth.size())\n",
    "    \n",
    "    loss = F.cross_entropy(logit, truth, reduce=is_average)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def metric(logit, truth, is_average=True):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = F.softmax(logit, 1)\n",
    "        value, top = prob.topk(3, dim=1, largest=True, sorted=True)\n",
    "        correct = top.eq(truth.view(-1, 1).expand_as(top))\n",
    "\n",
    "        if is_average==True:\n",
    "            # top-3 accuracy\n",
    "            correct = correct.float().sum(0, keepdim=False)\n",
    "            correct = correct/len(truth)\n",
    "\n",
    "            top = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "            precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "            return precision, top\n",
    "\n",
    "        else:\n",
    "            return correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "2e2f4b517477173b2caeb6f568db01c1c45acc5a"
   },
   "outputs": [],
   "source": [
    "# rate.py\n",
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string\n",
    "# https://github.com/pytorch/examples/blob/master/imagenet/main.py ###############\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "       lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr\n",
    "\n",
    "# file.py\n",
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "# http://stackoverflow.com/questions/34950201/pycharm-print-end-r-statement-not-working\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1 ):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "a554dfa49ece118b939b020b5590f3ddd6a2b62f"
   },
   "outputs": [],
   "source": [
    "# # train.py\n",
    "# def valid_augment(drawing, label, index):\n",
    "#     cache = Struct(drawing = drawing.copy(), label = label, index=index)\n",
    "#     image = drawing_to_temporal_image(drawing, 64, 64)\n",
    "# #     image = drawing_to_temporal_image(drawing, 32, 32)\n",
    "#     return image, label, cache\n",
    "\n",
    "\n",
    "# def train_augment(drawing, label, index):\n",
    "#     cache = Struct(drawing = drawing.copy(), label = label, index=index)\n",
    "#     ## <todo> augmentation ....\n",
    "#     image = drawing_to_temporal_image(drawing, 64, 64)\n",
    "# #     image = drawing_to_temporal_image(drawing, 32, 32)\n",
    "#     return image, label, cache\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### training ##############################################################\n",
    "\n",
    "def do_valid( net, valid_loader, criterion, max_iter = 3400000 ):\n",
    "\n",
    "    valid_num  = 0\n",
    "    probs    = []\n",
    "    truths   = []\n",
    "    losses   = []\n",
    "    corrects = []\n",
    "    \n",
    "    iter = 0\n",
    "    \n",
    "    for input, truth in valid_loader:\n",
    "        input = input.cuda().float()\n",
    "        truth = truth.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logit   = net(input)\n",
    "            prob    = F.softmax(logit,1)\n",
    "\n",
    "            loss    = criterion(logit, truth, False)\n",
    "            correct = metric(logit, truth, False)\n",
    "\n",
    "        valid_num += len(input)\n",
    "        probs.append(prob.data.cpu().numpy())\n",
    "        losses.append(loss.data.cpu().numpy())\n",
    "        corrects.append(correct.data.cpu().numpy())\n",
    "        truths.append(truth.data.cpu().numpy())\n",
    "        \n",
    "        if iter >= max_iter:\n",
    "            break\n",
    "        else:\n",
    "            iter += 1\n",
    "\n",
    "#     assert(valid_num == len(valid_loader.sampler))\n",
    "    #------------------------------------------------------\n",
    "    prob    = np.concatenate(probs)\n",
    "    correct = np.concatenate(corrects)\n",
    "    truth   = np.concatenate(truths).astype(np.int32).reshape(-1,1)\n",
    "    loss    = np.concatenate(losses)\n",
    "\n",
    "\n",
    "    #---\n",
    "    #top = np.argsort(-predict,1)[:,:3]\n",
    "\n",
    "    loss    = loss.mean()\n",
    "    correct = correct.mean(0)\n",
    "\n",
    "    top = [correct[0], correct[0]+correct[1], correct[0]+correct[1]+correct[2]]\n",
    "    precision = correct[0]/1 + correct[1]/2 + correct[2]/3\n",
    "\n",
    "    #----\n",
    "    valid_loss = np.array([\n",
    "        loss, top[0], top[2], precision\n",
    "    ])\n",
    "\n",
    "    return valid_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "944c65e5e6f9d14d3e4f94d56ab1a4e9afd94858",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [START 2018-11-14_17-20-28] ----------------------------------------------------------------\n",
      "\n",
      "\tSEED         = 35202\n",
      "\tPROJECT_PATH = .\n",
      "\tout_dir      = ../output_ensemble\n",
      "\n",
      "\t<additional comments>\n",
      "\t  ... xxx baseline  ... \n",
      "\n",
      "** dataset setting **\n",
      "batch_size = 128\n",
      "train_dataset : \n",
      "<__main__.PredictionDataset object at 0x7fbb923c4278>\n",
      "valid_dataset : \n",
      "<__main__.PredictionDataset object at 0x7fbb923c43c8>\n",
      "\n",
      "** net setting **\n",
      "<class '__main__.Ensemble'>\n",
      "criterion=<function softmax_cross_entropy_criterion at 0x7fbb45858b70>\n",
      "\n",
      "schduler\n",
      "  NullScheduler\n",
      "lr=0.01000 \n",
      "\n",
      "** start training here! **\n",
      "                    |------------ VALID -------------|-------- TRAIN/BATCH ----------|         \n",
      "rate   iter  epoch  | loss   acc-1  acc-3   lb       | loss   acc-1  acc-3   lb      |  time   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0100   0.0    0.0 | 0.000  0.000  0.000  (0.000)   | 6.448  0.062  0.086  (0.072)  |  0 hr 00 min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0100   1.0    0.0 | 0.000  0.000  0.000  (0.000)   | 1.170  0.820  0.953  (0.883)  |  0 hr 01 min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0100   1.0    0.0 | 0.952  0.845  0.956  (0.896)   | 0.923  0.850  0.958  (0.900)  |  0 hr 01 min\n",
      "0.0100   2.0    0.1 | 0.944  0.846  0.955  (0.896)*  | 0.947  0.851  0.954  (0.898)  |  0 hr 03 min\n",
      "0.0100   3.0    0.1 | 0.947  0.847  0.956  (0.897)   | 0.924  0.855  0.951  (0.898)  |  0 hr 04 min\n",
      "0.0100   3.1    0.1 | 0.947  0.847  0.956  (0.897)   | 0.689  0.898  0.953  (0.926)  |  0 hr 04 min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-30-956ebedd55eb>\", line 43, in __getitem__\n",
      "    pred4 = np_uint8_to_float32(pred4)\n",
      "  File \"<ipython-input-29-7ea857a5d4b2>\", line 2, in np_uint8_to_float32\n",
      "    return (x/scale).astype(np.float32)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-30-956ebedd55eb>\", line 20, in __getitem__\n",
      "    row = self.df.iloc[index]\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1478, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexing.py\", line 2095, in _getitem_axis\n",
      "    key = self._convert_scalar_indexer(key, axis)\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexing.py\", line 259, in _convert_scalar_indexer\n",
      "    ax = self.obj._get_axis(min(axis, self.ndim - 1))\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/generic.py\", line 391, in _get_axis\n",
      "    name = self._get_axis_name(axis)\n",
      "  File \"/home/cheeseprata/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/generic.py\", line 379, in _get_axis_name\n",
      "    if isinstance(axis, string_types):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-6b98fc4ff318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_train_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-32d29640f7ef>\u001b[0m in \u001b[0;36mrun_train_ensemble\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;31m#         for input, truth, cache in train_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_train_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
